{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33bf52b0-150b-4f77-996c-938a6006aeb5",
   "metadata": {},
   "source": [
    "# Instituto de Educação Superior de Brası́lia – IESB\n",
    "## Pós-Graduação em Inteligência Artificial\n",
    "### Disciplina de Computação Cognitiva 3 / Turma 2021-1\n",
    "#### Trabalho Final - Análise de Sentimento\n",
    "\n",
    "                          EQUIPE:\n",
    "                          - LUCAS DE SOUSA BRITO, MAT:2186330019, TURMA: 2021-1\n",
    "                          - PABLO NOGUEIRA OLIVEIRA, MAT:2186330027, TURMA: 2021-1\n",
    "                          - MATHEUS BARBOSA OLIVEIRA, MAT:2186330037, TURMA: 2021-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c69181-56d4-458d-bf05-9afd6d160fbf",
   "metadata": {},
   "source": [
    "# Análise de sentimento da base do twitter Sentiment140\n",
    "\n",
    "### Dados de Origem\n",
    "\n",
    "* http://help.sentiment140.com/for-students\n",
    "\n",
    "| sentiment  | id | date | query_string | user | text\n",
    "| ---        | -- | -    | -            | -    | ---\n",
    "| 0=negativo | -  | -    | -            | -    | the original twitter message\n",
    "| 2=neutro   | -  | -    | -            | -    | \n",
    "| 4=positivo | -  | -    | -            | -    |\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db53ecd9-3004-4394-84ce-1b8c0ac9197f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e6b0eb-bfa5-445a-a048-708af3376fcc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(129783)\n",
    "np.random.seed(3213)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ba5b0-b53f-462b-b9c3-886faed5100f",
   "metadata": {},
   "source": [
    "# Importação\n",
    "\n",
    "Dados de origem: \n",
    "* http://help.sentiment140.com/for-students\n",
    "* colunas:\n",
    "   * sentiment (0=negativo, 2=neutro, 4=positivo)\n",
    "   * id\n",
    "   * date\n",
    "   * query_string\n",
    "   * user\n",
    "   * text\n",
    "\n",
    "Para este exercício:\n",
    "* apenas as colunas sentiment e text serão mantidas\n",
    "* sentimentos neutros serão descartados\n",
    "* sentimentos serão padronizados como 0=negativo e 1=positivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440c278b-5bef-4de3-a45c-af0a2de36e52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>0</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>0</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>0</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>0</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>0</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text\n",
       "0                1  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1                1  is upset that he can't update his Facebook by ...\n",
       "2                1  @Kenichan I dived many times for the ball. Man...\n",
       "3                1    my whole body feels itchy and like its on fire \n",
       "4                1  @nationwideclass no, it's not behaving at all....\n",
       "...            ...                                                ...\n",
       "1599995          0  Just woke up. Having no school is the best fee...\n",
       "1599996          0  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997          0  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998          0  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999          0  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bloco():\n",
    "    \n",
    "    global df_original\n",
    "    \n",
    "    df_cols = ['sentiment','id','date','query_string','user','text']\n",
    "\n",
    "    df_original = pd.read_csv(\n",
    "        \"training.1600000.processed.noemoticon.csv\",\n",
    "        header=None, \n",
    "        names=df_cols,\n",
    "        encoding = \"ISO-8859-1\"\n",
    "    )\n",
    "\n",
    "    df_original.drop(\n",
    "        ['id','date','query_string','user'],\n",
    "        axis=1,\n",
    "        inplace=True\n",
    "    )\n",
    "    df_original = df_original[ df_original['sentiment'] != 2 ] \n",
    "    df_original['sentiment'] = df_original['sentiment'].apply( lambda x: 1 if x==0 else 0 )\n",
    "    return df_original\n",
    "\n",
    "bloco()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ecf111-1a77-4ecf-95ec-e6fdebe3463c",
   "metadata": {},
   "source": [
    "# Padronização (1)\n",
    "\n",
    "* Parte 1\n",
    "  * remove todas as tags\n",
    "  * remove urls\n",
    "  * remove identificadores de usuários \n",
    "  * remove caracteres unicode inválidos\n",
    "  * remove carcteres não textuais\n",
    "  * transforma tudo para minúsculas\n",
    "* Parte 2\n",
    "  * tokeniza usando o keras\n",
    "* Parte 3\n",
    "  * separa base de treinamento e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7daebdb4-478d-4fb2-b91c-e0db4510368f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa5df7e-ecbd-46c3-bdab-5e27c16cb0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text2</th>\n",
       "      <th>text3</th>\n",
       "      <th>text4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562641</th>\n",
       "      <td>1</td>\n",
       "      <td>Eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "      <td>eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "      <td>[636, 1907, 1, 77, 212, 113, 4, 71, 9, 228, 15...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596542</th>\n",
       "      <td>0</td>\n",
       "      <td>@SarY_ChaN</td>\n",
       "      <td>chan</td>\n",
       "      <td>[5851]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557121</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, the question as to whether I should get ...</td>\n",
       "      <td>well  the question as to whether i should get ...</td>\n",
       "      <td>[74, 3, 957, 83, 2, 2288, 1, 135, 36, 31, 25, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176192</th>\n",
       "      <td>0</td>\n",
       "      <td>Picnic in the sun</td>\n",
       "      <td>picnic in the sun</td>\n",
       "      <td>[2392, 10, 3, 275]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400171</th>\n",
       "      <td>0</td>\n",
       "      <td>Good morning! i'm outside and its a beautiful ...</td>\n",
       "      <td>good morning  i m outside and its a beautiful ...</td>\n",
       "      <td>[32, 95, 1, 20, 392, 7, 68, 4, 328, 33, 497, 5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092245</th>\n",
       "      <td>0</td>\n",
       "      <td>@smoochyfroggy You wellcome! Have a nice Day!</td>\n",
       "      <td>you wellcome  have a nice day</td>\n",
       "      <td>[8, 42399, 19, 4, 132, 33]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213310</th>\n",
       "      <td>1</td>\n",
       "      <td>Why is it so impossible to get an egg cream he...</td>\n",
       "      <td>why is it so impossible to get an egg cream he...</td>\n",
       "      <td>[110, 9, 6, 18, 2393, 2, 36, 93, 2444, 656, 86...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026205</th>\n",
       "      <td>0</td>\n",
       "      <td>lady at olive garden garden ask me if i cared ...</td>\n",
       "      <td>lady at olive garden garden ask me if i cared ...</td>\n",
       "      <td>[756, 25, 4727, 894, 894, 613, 17, 70, 1, 9128...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842287</th>\n",
       "      <td>0</td>\n",
       "      <td>Looking for domains. Great deals only.</td>\n",
       "      <td>looking for domains  great deals only</td>\n",
       "      <td>[209, 11, 10294, 99, 6290, 112]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292903</th>\n",
       "      <td>1</td>\n",
       "      <td>not wasting my money on a piercing that has a ...</td>\n",
       "      <td>not wasting my money on a piercing that has a ...</td>\n",
       "      <td>[26, 4254, 5, 414, 15, 4, 5087, 16, 100, 4, 10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137835</th>\n",
       "      <td>1</td>\n",
       "      <td>@rishil I think I'm the bigger geek as I found...</td>\n",
       "      <td>i think i m the bigger geek as i found that g...</td>\n",
       "      <td>[1, 77, 1, 20, 3, 2048, 2360, 83, 1, 320, 16, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468447</th>\n",
       "      <td>0</td>\n",
       "      <td>the only person who Jackson Rathbone (jasper) ...</td>\n",
       "      <td>the only person who jackson rathbone  jasper  ...</td>\n",
       "      <td>[3, 112, 536, 154, 3380, 23267, 8071, 116, 19,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692576</th>\n",
       "      <td>1</td>\n",
       "      <td>My Indian place is at farmer's market today!!!...</td>\n",
       "      <td>my indian place is at farmer s market today   ...</td>\n",
       "      <td>[5, 3174, 407, 9, 25, 6691, 12, 1713, 41, 21, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910387</th>\n",
       "      <td>0</td>\n",
       "      <td>@fancyfantastic you know I love you.</td>\n",
       "      <td>you know i love you</td>\n",
       "      <td>[8, 59, 1, 46, 8]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039469</th>\n",
       "      <td>0</td>\n",
       "      <td>don't want to go to work but i have to pay off...</td>\n",
       "      <td>don t want to go to work but i have to pay off...</td>\n",
       "      <td>[62, 14, 76, 2, 40, 2, 45, 21, 1, 19, 2, 564, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text  \\\n",
       "562641           1  Eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...   \n",
       "1596542          0                                      @SarY_ChaN      \n",
       "557121           1  Well, the question as to whether I should get ...   \n",
       "1176192          0                                 Picnic in the sun    \n",
       "1400171          0  Good morning! i'm outside and its a beautiful ...   \n",
       "1092245          0     @smoochyfroggy You wellcome! Have a nice Day!    \n",
       "213310           1  Why is it so impossible to get an egg cream he...   \n",
       "1026205          0  lady at olive garden garden ask me if i cared ...   \n",
       "842287           0            Looking for domains. Great deals only.    \n",
       "292903           1  not wasting my money on a piercing that has a ...   \n",
       "137835           1  @rishil I think I'm the bigger geek as I found...   \n",
       "1468447          0  the only person who Jackson Rathbone (jasper) ...   \n",
       "692576           1  My Indian place is at farmer's market today!!!...   \n",
       "910387           0              @fancyfantastic you know I love you.    \n",
       "1039469          0  don't want to go to work but i have to pay off...   \n",
       "\n",
       "                                                     text2  \\\n",
       "562641   eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...   \n",
       "1596542                                            chan      \n",
       "557121   well  the question as to whether i should get ...   \n",
       "1176192                                 picnic in the sun    \n",
       "1400171  good morning  i m outside and its a beautiful ...   \n",
       "1092245                    you wellcome  have a nice day     \n",
       "213310   why is it so impossible to get an egg cream he...   \n",
       "1026205  lady at olive garden garden ask me if i cared ...   \n",
       "842287             looking for domains  great deals only     \n",
       "292903   not wasting my money on a piercing that has a ...   \n",
       "137835    i think i m the bigger geek as i found that g...   \n",
       "1468447  the only person who jackson rathbone  jasper  ...   \n",
       "692576   my indian place is at farmer s market today   ...   \n",
       "910387                               you know i love you     \n",
       "1039469  don t want to go to work but i have to pay off...   \n",
       "\n",
       "                                                     text3  \\\n",
       "562641   [636, 1907, 1, 77, 212, 113, 4, 71, 9, 228, 15...   \n",
       "1596542                                             [5851]   \n",
       "557121   [74, 3, 957, 83, 2, 2288, 1, 135, 36, 31, 25, ...   \n",
       "1176192                                 [2392, 10, 3, 275]   \n",
       "1400171  [32, 95, 1, 20, 392, 7, 68, 4, 328, 33, 497, 5...   \n",
       "1092245                         [8, 42399, 19, 4, 132, 33]   \n",
       "213310   [110, 9, 6, 18, 2393, 2, 36, 93, 2444, 656, 86...   \n",
       "1026205  [756, 25, 4727, 894, 894, 613, 17, 70, 1, 9128...   \n",
       "842287                     [209, 11, 10294, 99, 6290, 112]   \n",
       "292903   [26, 4254, 5, 414, 15, 4, 5087, 16, 100, 4, 10...   \n",
       "137835   [1, 77, 1, 20, 3, 2048, 2360, 83, 1, 320, 16, ...   \n",
       "1468447  [3, 112, 536, 154, 3380, 23267, 8071, 116, 19,...   \n",
       "692576   [5, 3174, 407, 9, 25, 6691, 12, 1713, 41, 21, ...   \n",
       "910387                                   [8, 59, 1, 46, 8]   \n",
       "1039469  [62, 14, 76, 2, 40, 2, 45, 21, 1, 19, 2, 564, ...   \n",
       "\n",
       "                                                     text4  \n",
       "562641   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1596542  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "557121   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1176192  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1400171  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1092245  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "213310   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1026205  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "842287   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "292903   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "137835   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1468447  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "692576   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "910387   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1039469  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_limit = 200000\n",
    "max_words = 100000\n",
    "max_len = 1000\n",
    "\n",
    "def bloco():\n",
    "    \n",
    "    global df_original\n",
    "    global df_train\n",
    "    global df_test   \n",
    "   \n",
    "    # PARTE 1 - Limpa o texto \n",
    "    import re\n",
    "    pat1 = r'@[A-Za-z0-9]+'\n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "    pat3 = r'<.*?>'\n",
    "    pat4 = r'&.*?;'\n",
    "    pat = r'|'.join((pat1, pat2, pat3, pat4))\n",
    "    def tweet_cleaner(text):       \n",
    "        text = re.sub(pat,'',text)\n",
    "        try:\n",
    "            text = text.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "        except:\n",
    "            text = text\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "        text = text.lower()\n",
    "        return text\n",
    "\n",
    "    df_original['text2'] = df_original['text'].apply( tweet_cleaner )\n",
    "\n",
    "    \n",
    "    # PARTE 2 - Tokeniza usando o Keras\n",
    "    global tokenizer\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words,lower=True, split=\" \")\n",
    "    tokenizer.fit_on_texts(df_original['text2'])\n",
    "    #df_original['text3'] = tokenizer.texts_to_sequences(df_original['text2'])\n",
    "    #df_original['text4'] = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    #    df_original['text3'], \n",
    "    #    maxlen=max_len,\n",
    "    #    #padding='post',\n",
    "    #    #truncating='post'        \n",
    "    #).tolist()                                                                                                   \n",
    "   \n",
    "\n",
    "    global df_example\n",
    "    df_example = df_original.sample(15)\n",
    "    df_example['text3'] = tokenizer.texts_to_sequences(df_example['text2'])\n",
    "    df_example['text4'] = tf.keras.preprocessing.sequence.pad_sequences( df_example['text3'], maxlen=max_len ).tolist()              \n",
    "        \n",
    "    # PARTE 3 - Separa amostra de treinamento e de teste\n",
    "   \n",
    "    # 1 = train | 0 = test\n",
    "    df_original['rand'] = pd.Series([0,1]).sample(len(df_original), replace=True).array\n",
    "    \n",
    "    df_train_sz = 10000\n",
    "    df_train = df_original[ df_original[ 'rand' ] == 1 ]\n",
    "    df_train_positive = df_train[ df_train['sentiment'] == 0 ].sample(n=int(df_train_sz/2), replace=True)\n",
    "    df_train_negative = df_train[ df_train['sentiment'] == 1 ].sample(n=int(df_train_sz/2), replace=True)\n",
    "    df_train = pd.concat( [ df_train_negative, df_train_positive ] )    \n",
    "    df_train = df_train.sample(frac=1.0).reset_index(drop=True)\n",
    "    \n",
    "    df_test_sz = 40000\n",
    "    df_test = df_original[ df_original[ 'rand' ] == 0 ].sample(int(df_test_sz/2), replace=True)\n",
    "    df_test = df_test.sample(frac=1.0).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "bloco()\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07e57a-8455-4496-b901-75bf0a9c7a3a",
   "metadata": {},
   "source": [
    "Na tabela acima é possível ver os estagios da limpeza:\n",
    "* **text** contém o texto original da base \n",
    "* **text2** contém o texto após limpeza de tags, urls, nomes de usuário, números e minusculas\n",
    "* **text3** contém o texto codificado em \"embeddings\" pelo tensorflow. Cada palavra foi convertida em um número. \n",
    "* **text4** contém o texto codificado em \"embeddings\" com o padding. Só aparecem zeros aqui pois uma coluna com 1,2,3 em text3 será codificada como 0,0,0,0[...],1,2,3. Como é raro encontrar um tweet com mais de 180 palavras, o início é quase sempre [0,0,0,0,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287581a-38e5-450c-9d8f-ba1c83f12161",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4370bdf-cc7d-4c11-8c86-a689cddb5c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:13:18.907239: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-26 18:13:18.907305: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: lucas-n001\n",
      "2022-05-26 18:13:18.907317: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: lucas-n001\n",
      "2022-05-26 18:13:18.907455: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.73.5\n",
      "2022-05-26 18:13:18.907508: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-26 18:13:18.907519: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.73.5\n",
      "2022-05-26 18:13:18.907967: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()         \n",
    "model.add(tf.keras.layers.Embedding(max_words, 16, mask_zero=True))\n",
    "model.add(tf.keras.layers.LSTM(16))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10907d22-fe7b-42f4-9113-8ef5c0b141e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          1600000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 16)                2112      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1088      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,603,265\n",
      "Trainable params: 1,603,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "model.compile(\n",
    "    #optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001,momentum=0.5),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\n",
    "        'acc',        \n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tfa.metrics.F1Score(num_classes=1, threshold=0.5, name='f1')\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ffe26f-d9f7-4695-91b1-08d14b2b2971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(10000, 1000) y.shape=(10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences( tokenizer.texts_to_sequences( df_train['text2'] ), maxlen=max_len )\n",
    "y_train = df_train['sentiment'].values\n",
    "\n",
    "print( f'X.shape={X_train.shape} y.shape={y_train.shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf989e9-9000-43ea-b2da-efec2943078e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "27/27 [==============================] - 39s 1s/step - loss: 0.6930 - acc: 0.5196 - prec: 0.5204 - recall: 0.5376 - f1: 0.5289 - val_loss: 0.6928 - val_acc: 0.5470 - val_prec: 0.5409 - val_recall: 0.5486 - val_f1: 0.5447 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6928 - acc: 0.5439 - prec: 0.5401 - recall: 0.6092 - f1: 0.5726 - val_loss: 0.6926 - val_acc: 0.5635 - val_prec: 0.5445 - val_recall: 0.7115 - val_f1: 0.6169 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.6925 - acc: 0.5525 - prec: 0.5473 - recall: 0.6234 - f1: 0.5828 - val_loss: 0.6923 - val_acc: 0.6040 - val_prec: 0.6049 - val_recall: 0.5719 - val_f1: 0.5879 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6922 - acc: 0.5709 - prec: 0.5699 - recall: 0.5885 - f1: 0.5790 - val_loss: 0.6919 - val_acc: 0.6045 - val_prec: 0.5901 - val_recall: 0.6528 - val_f1: 0.6199 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6916 - acc: 0.5889 - prec: 0.5828 - recall: 0.6341 - f1: 0.6074 - val_loss: 0.6913 - val_acc: 0.6170 - val_prec: 0.6076 - val_recall: 0.6346 - val_f1: 0.6208 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6909 - acc: 0.6008 - prec: 0.6036 - recall: 0.5940 - f1: 0.5987 - val_loss: 0.6906 - val_acc: 0.6300 - val_prec: 0.6223 - val_recall: 0.6387 - val_f1: 0.6304 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6902 - acc: 0.6089 - prec: 0.6050 - recall: 0.6338 - f1: 0.6191 - val_loss: 0.6896 - val_acc: 0.6395 - val_prec: 0.6482 - val_recall: 0.5911 - val_f1: 0.6183 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.6888 - acc: 0.6286 - prec: 0.6325 - recall: 0.6191 - f1: 0.6258 - val_loss: 0.6882 - val_acc: 0.6465 - val_prec: 0.6532 - val_recall: 0.6063 - val_f1: 0.6289 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6871 - acc: 0.6426 - prec: 0.6486 - recall: 0.6271 - f1: 0.6377 - val_loss: 0.6863 - val_acc: 0.6565 - val_prec: 0.6720 - val_recall: 0.5951 - val_f1: 0.6312 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6845 - acc: 0.6515 - prec: 0.6643 - recall: 0.6167 - f1: 0.6396 - val_loss: 0.6837 - val_acc: 0.6605 - val_prec: 0.6656 - val_recall: 0.6285 - val_f1: 0.6465 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.6813 - acc: 0.6612 - prec: 0.6680 - recall: 0.6453 - f1: 0.6564 - val_loss: 0.6801 - val_acc: 0.6690 - val_prec: 0.6620 - val_recall: 0.6741 - val_f1: 0.6680 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6769 - acc: 0.6765 - prec: 0.6748 - recall: 0.6852 - f1: 0.6799 - val_loss: 0.6752 - val_acc: 0.6750 - val_prec: 0.6821 - val_recall: 0.6407 - val_f1: 0.6608 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6705 - acc: 0.6831 - prec: 0.6901 - recall: 0.6682 - f1: 0.6790 - val_loss: 0.6686 - val_acc: 0.6805 - val_prec: 0.6797 - val_recall: 0.6680 - val_f1: 0.6738 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6623 - acc: 0.6877 - prec: 0.6888 - recall: 0.6884 - f1: 0.6886 - val_loss: 0.6601 - val_acc: 0.6850 - val_prec: 0.6715 - val_recall: 0.7095 - val_f1: 0.6900 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6516 - acc: 0.6981 - prec: 0.6953 - recall: 0.7086 - f1: 0.7019 - val_loss: 0.6496 - val_acc: 0.6865 - val_prec: 0.6814 - val_recall: 0.6862 - val_f1: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.6386 - acc: 0.7038 - prec: 0.7025 - recall: 0.7099 - f1: 0.7062 - val_loss: 0.6384 - val_acc: 0.6930 - val_prec: 0.6802 - val_recall: 0.7146 - val_f1: 0.6969 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6245 - acc: 0.7104 - prec: 0.7048 - recall: 0.7271 - f1: 0.7157 - val_loss: 0.6271 - val_acc: 0.6985 - val_prec: 0.6849 - val_recall: 0.7217 - val_f1: 0.7028 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.6110 - acc: 0.7218 - prec: 0.7097 - recall: 0.7532 - f1: 0.7308 - val_loss: 0.6174 - val_acc: 0.7055 - val_prec: 0.7111 - val_recall: 0.6802 - val_f1: 0.6953 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.5987 - acc: 0.7253 - prec: 0.7287 - recall: 0.7203 - f1: 0.7245 - val_loss: 0.6091 - val_acc: 0.7035 - val_prec: 0.6981 - val_recall: 0.7045 - val_f1: 0.7013 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.5843 - acc: 0.7344 - prec: 0.7365 - recall: 0.7323 - f1: 0.7344 - val_loss: 0.6024 - val_acc: 0.7095 - val_prec: 0.6947 - val_recall: 0.7348 - val_f1: 0.7142 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.5735 - acc: 0.7430 - prec: 0.7368 - recall: 0.7585 - f1: 0.7475 - val_loss: 0.5952 - val_acc: 0.7140 - val_prec: 0.7063 - val_recall: 0.7206 - val_f1: 0.7134 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.5614 - acc: 0.7516 - prec: 0.7491 - recall: 0.7590 - f1: 0.7540 - val_loss: 0.5886 - val_acc: 0.7190 - val_prec: 0.7080 - val_recall: 0.7338 - val_f1: 0.7207 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.5485 - acc: 0.7601 - prec: 0.7595 - recall: 0.7635 - f1: 0.7615 - val_loss: 0.5824 - val_acc: 0.7200 - val_prec: 0.7110 - val_recall: 0.7298 - val_f1: 0.7203 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.5338 - acc: 0.7695 - prec: 0.7709 - recall: 0.7689 - f1: 0.7699 - val_loss: 0.5770 - val_acc: 0.7215 - val_prec: 0.7086 - val_recall: 0.7409 - val_f1: 0.7244 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.5220 - acc: 0.7793 - prec: 0.7748 - recall: 0.7891 - f1: 0.7819 - val_loss: 0.5716 - val_acc: 0.7240 - val_prec: 0.7150 - val_recall: 0.7338 - val_f1: 0.7243 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.5055 - acc: 0.7870 - prec: 0.7865 - recall: 0.7896 - f1: 0.7881 - val_loss: 0.5672 - val_acc: 0.7215 - val_prec: 0.7090 - val_recall: 0.7399 - val_f1: 0.7241 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.4955 - acc: 0.7949 - prec: 0.7896 - recall: 0.8056 - f1: 0.7975 - val_loss: 0.5634 - val_acc: 0.7280 - val_prec: 0.7289 - val_recall: 0.7156 - val_f1: 0.7222 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.4824 - acc: 0.7991 - prec: 0.8000 - recall: 0.7994 - f1: 0.7997 - val_loss: 0.5600 - val_acc: 0.7315 - val_prec: 0.7133 - val_recall: 0.7632 - val_f1: 0.7374 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.4724 - acc: 0.8096 - prec: 0.8077 - recall: 0.8143 - f1: 0.8110 - val_loss: 0.5561 - val_acc: 0.7350 - val_prec: 0.7267 - val_recall: 0.7429 - val_f1: 0.7347 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.4591 - acc: 0.8148 - prec: 0.8130 - recall: 0.8190 - f1: 0.8160 - val_loss: 0.5533 - val_acc: 0.7390 - val_prec: 0.7312 - val_recall: 0.7460 - val_f1: 0.7385 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.4472 - acc: 0.8209 - prec: 0.8225 - recall: 0.8198 - f1: 0.8211 - val_loss: 0.5523 - val_acc: 0.7380 - val_prec: 0.7283 - val_recall: 0.7490 - val_f1: 0.7385 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.4355 - acc: 0.8300 - prec: 0.8287 - recall: 0.8333 - f1: 0.8310 - val_loss: 0.5512 - val_acc: 0.7360 - val_prec: 0.7273 - val_recall: 0.7449 - val_f1: 0.7360 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.4214 - acc: 0.8324 - prec: 0.8307 - recall: 0.8362 - f1: 0.8334 - val_loss: 0.5510 - val_acc: 0.7370 - val_prec: 0.7319 - val_recall: 0.7379 - val_f1: 0.7349 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.4116 - acc: 0.8394 - prec: 0.8374 - recall: 0.8435 - f1: 0.8404 - val_loss: 0.5541 - val_acc: 0.7355 - val_prec: 0.7311 - val_recall: 0.7348 - val_f1: 0.7330 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.4037 - acc: 0.8431 - prec: 0.8445 - recall: 0.8422 - f1: 0.8434 - val_loss: 0.5547 - val_acc: 0.7395 - val_prec: 0.7305 - val_recall: 0.7490 - val_f1: 0.7396 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.3924 - acc: 0.8471 - prec: 0.8465 - recall: 0.8492 - f1: 0.8478 - val_loss: 0.5561 - val_acc: 0.7380 - val_prec: 0.7306 - val_recall: 0.7439 - val_f1: 0.7372 - lr: 8.0000e-05\n",
      "Epoch 37/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.3852 - acc: 0.8528 - prec: 0.8511 - recall: 0.8562 - f1: 0.8536 - val_loss: 0.5571 - val_acc: 0.7365 - val_prec: 0.7280 - val_recall: 0.7449 - val_f1: 0.7364 - lr: 8.0000e-05\n",
      "Epoch 38/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.3764 - acc: 0.8569 - prec: 0.8577 - recall: 0.8567 - f1: 0.8572 - val_loss: 0.5602 - val_acc: 0.7400 - val_prec: 0.7263 - val_recall: 0.7601 - val_f1: 0.7428 - lr: 6.4000e-05\n",
      "Epoch 39/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.3703 - acc: 0.8618 - prec: 0.8591 - recall: 0.8664 - f1: 0.8627 - val_loss: 0.5622 - val_acc: 0.7390 - val_prec: 0.7298 - val_recall: 0.7490 - val_f1: 0.7393 - lr: 6.4000e-05\n",
      "Epoch 40/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.3642 - acc: 0.8631 - prec: 0.8658 - recall: 0.8604 - f1: 0.8631 - val_loss: 0.5642 - val_acc: 0.7380 - val_prec: 0.7266 - val_recall: 0.7530 - val_f1: 0.7396 - lr: 5.1200e-05\n",
      "Epoch 41/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.3591 - acc: 0.8656 - prec: 0.8668 - recall: 0.8649 - f1: 0.8659 - val_loss: 0.5674 - val_acc: 0.7390 - val_prec: 0.7280 - val_recall: 0.7530 - val_f1: 0.7403 - lr: 5.1200e-05\n",
      "Epoch 42/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.3535 - acc: 0.8719 - prec: 0.8720 - recall: 0.8726 - f1: 0.8723 - val_loss: 0.5692 - val_acc: 0.7390 - val_prec: 0.7262 - val_recall: 0.7571 - val_f1: 0.7413 - lr: 4.0960e-05\n",
      "Epoch 43/60\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.3494 - acc: 0.8705 - prec: 0.8700 - recall: 0.8721 - f1: 0.8710 - val_loss: 0.5716 - val_acc: 0.7385 - val_prec: 0.7282 - val_recall: 0.7510 - val_f1: 0.7394 - lr: 4.0960e-05\n",
      "Epoch 44/60\n",
      "27/27 [==============================] - 30s 1s/step - loss: 0.3469 - acc: 0.8730 - prec: 0.8743 - recall: 0.8721 - f1: 0.8732 - val_loss: 0.5731 - val_acc: 0.7385 - val_prec: 0.7282 - val_recall: 0.7510 - val_f1: 0.7394 - lr: 3.2768e-05\n"
     ]
    }
   ],
   "source": [
    "my_callbacks = [\n",
    "        # abandona o processamento se a acurácia não melhorar em até {patitence} épocas\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_acc',patience=6), \n",
    "        # grava os modelos intermediários\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath='model/model.{epoch:02d}.h5'), # salva o modelo para poder retomar o treinamento\n",
    "        # grava informações para visualização\n",
    "        # tf.keras.callbacks.TensorBoard(log_dir='./logs'), \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, min_lr=0.00001)\n",
    "    ]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=60,\n",
    "    batch_size=300,\n",
    "    validation_split=0.20,\n",
    "    callbacks=my_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2887c40d-84c0-488f-b08d-084725b5c7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bloco():\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, ax = plt.subplots(2,1,figsize=(16,6))\n",
    "    ax[0].plot(history.history['val_loss'], color='#FF0000', label=\"val_loss\")\n",
    "    ax[0].plot(history.history['loss'], color='#FFA0A0', label=\"loss\")\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "        \n",
    "    ax[1].plot(history.history['val_acc'], color='#00FF00', label=\"val_acc\")\n",
    "    ax[1].plot(history.history['acc'], color='#A0FFA0', label=\"acc\")\n",
    "    ax[1].set_ylim([0.0,1.0])\n",
    "    legend = ax[1].legend(loc='best', shadow=True)        \n",
    "    \n",
    "bloco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5fc9b1-b997-4b00-9dc1-d7883d0d4f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seleciona o modelo com maior acurácia durante a validação (usualmente antes do overfit)\n",
      "melhor epoca: 38 val_acc=0.74\n"
     ]
    }
   ],
   "source": [
    "def bloco():\n",
    "    \n",
    "    print( 'Seleciona o modelo com maior acurácia durante a validação (usualmente antes do overfit)' )\n",
    "    \n",
    "    best_acc = max(history.history['val_acc'])\n",
    "    best_epoch = history.history['val_acc'].index(best_acc) + 1\n",
    "    \n",
    "    print( f'melhor epoca: {best_epoch} val_acc={best_acc:1.2f}' )    \n",
    "        \n",
    "    model.load_weights( f'model/model.{best_epoch:02d}.h5' )\n",
    "\n",
    "bloco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3082774-9c0e-4bc3-ab29-e2264ff2f4da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 74s 115ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi guys!  I have been dying to Tweet you.........</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watching the MTV awards wishing i was cool eno...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going to shop with my BFF today, it's gonn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alot of new pictures tweets  ; some really old...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scariest words ever, &amp;quot;Mommy, I cant breat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>ahhh Time to relax babies are in bed.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>@NarelleKylie I missed you  boohoo!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>I still cann't vote on Mr twitter. The &amp;quot;+...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>it is so hot that i am totally melting now</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>My boy came home with food.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  predicted\n",
       "0      Hi guys!  I have been dying to Tweet you.........          0          0\n",
       "1      watching the MTV awards wishing i was cool eno...          1          0\n",
       "2      I'm going to shop with my BFF today, it's gonn...          0          0\n",
       "3      alot of new pictures tweets  ; some really old...          0          0\n",
       "4      Scariest words ever, &quot;Mommy, I cant breat...          1          1\n",
       "...                                                  ...        ...        ...\n",
       "19995             ahhh Time to relax babies are in bed.           0          0\n",
       "19996                @NarelleKylie I missed you  boohoo!          1          1\n",
       "19997  I still cann't vote on Mr twitter. The &quot;+...          1          1\n",
       "19998       it is so hot that i am totally melting now            1          1\n",
       "19999                       My boy came home with food.           0          1\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tf.keras.preprocessing.sequence.pad_sequences( tokenizer.texts_to_sequences( df_test['text2'] ), maxlen=max_len )\n",
    "y_test = df_test['sentiment'].values\n",
    "y_pred = [ 1 if y_pred > 0.5 else 0 for y_pred in model.predict(X_test).reshape(len(X_test)) ]\n",
    "\n",
    "df_test['predicted'] = y_pred\n",
    "df_test[ ['text','sentiment','predicted'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7b78808-bba4-4c29-ba9b-41103ea63cc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "        <style>\n",
       "           .luc_confusion_mtx td { background: white!IMPORTANT; border: 0pt !IMPORTANT; text-align: center!IMPORTANT }           \n",
       "           td.luc_confusion_mtx_dp { width: 90pt; height: 90pt; background: #c0ffc0!IMPORTANT; border: 1pt solid black!IMPORTANT } \n",
       "           td.luc_confusion_mtx_dn { width: 90pt; height: 90pt; background: #ffc0c0!IMPORTANT; border: 1pt solid black!IMPORTANT }            \n",
       "        </style>\n",
       "        \n",
       "               \n",
       "        <table class='luc_confusion_mtx'>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td colspan=2>Previsão</td>\n",
       "            <td></td>\n",
       "            <td rowspan=5 style='text-align: left!IMPORTANT'>\n",
       "                    Acurácia<br><big><big>(TP+TN)/(total)</big></big> = 14669/20000 = <big>73.3%</big><br>\n",
       "                    <br><br>\n",
       "                    Considerando que as duas classes (0=sentimento negativo;1=sentimento positivo) tem igual \n",
       "                    valor para esta análise, é importante maximizar a diagonal verde / minimizar a diagonal vermelha,\n",
       "                    portanto os indicadores de Acurácia OU F1 são os mais indicados.<br>\n",
       "                    <br>\n",
       "                    Os indicadores de precisão e sensibilidade(recall) podem ser usados em conjunto, mas não são\n",
       "                    muito intuitivos para este conjunto de dados pois mensuram da perspectiva do \"sentimento positivo\".\n",
       "                    Em outras palavras, a sensibilidade indica quantos \"sentimentos positivos\" corretos foram encontrados\n",
       "                    e a \"precisão\" indica do total apontado pelo modelo como \"sentimento positivo\", quantos eram. \n",
       "            </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td>Negativo</td>\n",
       "            <td>Positivo</td>\n",
       "            <td></td>            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td rowspan=2>Real</td>\n",
       "            <td>Negativo</td>\n",
       "            <td class=\"luc_confusion_mtx_dp\"><big><big>TN</big></big><br>7151<br>35.8%</td>\n",
       "            <td class=\"luc_confusion_mtx_dn\"><big><big>FP</big></big><br>2742<br>13.7%</td>\n",
       "            <td>9893</td>\n",
       "        </tr>        \n",
       "        <tr>\n",
       "            <td>Positivo</td>\n",
       "            <td class=\"luc_confusion_mtx_dn\"><big><big>FN</big></big><br>2589<br>12.9%</td>\n",
       "            <td class=\"luc_confusion_mtx_dp\"><big><big>TP</big></big><br>7518<br>37.6%</td>\n",
       "            <td>5331</td>\n",
       "        </tr>  \n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td>9740</td>\n",
       "            <td>10260</td>\n",
       "            <td>20000</td>\n",
       "        </tr>  \n",
       "        </table>    \n",
       "        \n",
       "        \n",
       "       \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Acurácia=73.34% dos apontamentos positivos e negativos estão corretos\n",
      " Recall/Sensibilidade=74.38% dos sentimentos positivos da base foram apontados\n",
      "             Precisão=73.27% dos sentimentos positivos apontados estão corretos\n",
      "             F1 Score=73.86% média harmônica da acurácia e recall\n"
     ]
    }
   ],
   "source": [
    "def block():\n",
    "    \n",
    "    global confusion_mtx\n",
    "    global confusion_mtx_pc\n",
    "    \n",
    "    confusion_mtx = tf.math.confusion_matrix( y_test, y_pred )\n",
    "\n",
    "    confusion_mtx = pd.DataFrame( confusion_mtx )\n",
    "    confusion_mtx.loc['Total'] = confusion_mtx.sum(numeric_only=True) \n",
    "    confusion_mtx['total'] = confusion_mtx[0] + confusion_mtx[1]\n",
    "    \n",
    "    confusion_mtx_pc = confusion_mtx / len(y_test)\n",
    "    \n",
    "    fp = confusion_mtx.iloc[0,1] \n",
    "    fn = confusion_mtx.iloc[1,0]\n",
    "    tn = confusion_mtx.iloc[0,0]\n",
    "    tp = confusion_mtx.iloc[1,1] \n",
    "    \n",
    "    total = (tp+tn+fp+fn)\n",
    "    \n",
    "    acc       = (tp+tn)/(tp+tn+fp+fn)\n",
    "    recall    = tp/(tp+fn)\n",
    "    f1        = (2*acc*recall)/(acc+recall)\n",
    "    \n",
    "    fdr  = fp/(fp+tp)\n",
    "    fnr  = fn/(fn+tp)\n",
    "    \n",
    "    tpr = tp/(fn+tp)\n",
    "    ppv  = tp/(fp+tp)\n",
    "    \n",
    "    \n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(f\"\"\"\n",
    "    \n",
    "        <style>\n",
    "           .luc_confusion_mtx td {{ background: white!IMPORTANT; border: 0pt !IMPORTANT; text-align: center!IMPORTANT }}           \n",
    "           td.luc_confusion_mtx_dp {{ width: 90pt; height: 90pt; background: #c0ffc0!IMPORTANT; border: 1pt solid black!IMPORTANT }} \n",
    "           td.luc_confusion_mtx_dn {{ width: 90pt; height: 90pt; background: #ffc0c0!IMPORTANT; border: 1pt solid black!IMPORTANT }}            \n",
    "        </style>\n",
    "        \n",
    "               \n",
    "        <table class='luc_confusion_mtx'>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td colspan=2>Previsão</td>\n",
    "            <td></td>\n",
    "            <td rowspan=5 style='text-align: left!IMPORTANT'>\n",
    "                    Acurácia<br><big><big>(TP+TN)/(total)</big></big> = {tp+tn}/{total} = <big>{(tp+tn)*100.0/total:2.1f}%</big><br>\n",
    "                    <br><br>\n",
    "                    Considerando que as duas classes (0=sentimento negativo;1=sentimento positivo) tem igual \n",
    "                    valor para esta análise, é importante maximizar a diagonal verde / minimizar a diagonal vermelha,\n",
    "                    portanto os indicadores de Acurácia OU F1 são os mais indicados.<br>\n",
    "                    <br>\n",
    "                    Os indicadores de precisão e sensibilidade(recall) podem ser usados em conjunto, mas não são\n",
    "                    muito intuitivos para este conjunto de dados pois mensuram da perspectiva do \"sentimento positivo\".\n",
    "                    Em outras palavras, a sensibilidade indica quantos \"sentimentos positivos\" corretos foram encontrados\n",
    "                    e a \"precisão\" indica do total apontado pelo modelo como \"sentimento positivo\", quantos eram. \n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>Negativo</td>\n",
    "            <td>Positivo</td>\n",
    "            <td></td>            \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=2>Real</td>\n",
    "            <td>Negativo</td>\n",
    "            <td class=\"luc_confusion_mtx_dp\"><big><big>TN</big></big><br>{tn}<br>{tn*100.0/total:2.1f}%</td>\n",
    "            <td class=\"luc_confusion_mtx_dn\"><big><big>FP</big></big><br>{fp}<br>{fp*100.0/total:2.1f}%</td>\n",
    "            <td>{tn+fp}</td>\n",
    "        </tr>        \n",
    "        <tr>\n",
    "            <td>Positivo</td>\n",
    "            <td class=\"luc_confusion_mtx_dn\"><big><big>FN</big></big><br>{fn}<br>{fn*100.0/total:2.1f}%</td>\n",
    "            <td class=\"luc_confusion_mtx_dp\"><big><big>TP</big></big><br>{tp}<br>{tp*100.0/total:2.1f}%</td>\n",
    "            <td>{fn+fp}</td>\n",
    "        </tr>  \n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>{tn+fn}</td>\n",
    "            <td>{fp+tp}</td>\n",
    "            <td>{total}</td>\n",
    "        </tr>  \n",
    "        </table>    \n",
    "        \n",
    "        \n",
    "       \n",
    "    \"\"\"))        \n",
    "    \n",
    "    print( f'             Acurácia={acc*100.0:05.2f}% dos apontamentos positivos e negativos estão corretos' )\n",
    "    print( f' Recall/Sensibilidade={tpr*100.0:05.2f}% dos sentimentos positivos da base foram apontados' )   \n",
    "    print( f'             Precisão={ppv*100.0:05.2f}% dos sentimentos positivos apontados estão corretos' )    \n",
    "    print( f'             F1 Score={f1*100.0:05.2f}% média harmônica da acurácia e recall' )        \n",
    "      \n",
    "\n",
    "    \n",
    "block()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b8407-9462-4823-9496-e6da6f55d6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "venv_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
