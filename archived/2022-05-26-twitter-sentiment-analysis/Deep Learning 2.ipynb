{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5721be0e-4d87-4138-bebb-a488ea8f9fb9",
   "metadata": {},
   "source": [
    "# Instituto de Educação Superior de Brası́lia – IESB\n",
    "## Pós-Graduação em Inteligência Artificial\n",
    "### Disciplina de Computação Cognitiva 3 / Turma 2021-1\n",
    "#### Trabalho Final - Análise de Sentimento\n",
    "\n",
    "                          EQUIPE:\n",
    "                          - LUCAS DE SOUSA BRITO, MAT:2186330019, TURMA: 2021-1\n",
    "                          - PABLO NOGUEIRA OLIVEIRA, MAT:2186330027, TURMA: 2021-1\n",
    "                          - MATHEUS BARBOSA OLIVEIRA, MAT:2186330037, TURMA: 2021-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c69181-56d4-458d-bf05-9afd6d160fbf",
   "metadata": {},
   "source": [
    "# Análise de sentimento da base do twitter Sentiment140\n",
    "\n",
    "### Dados de Origem\n",
    "\n",
    "* http://help.sentiment140.com/for-students\n",
    "\n",
    "| sentiment  | id | date | query_string | user | text\n",
    "| ---        | -- | -    | -            | -    | ---\n",
    "| 0=negativo | -  | -    | -            | -    | the original twitter message\n",
    "| 2=neutro   | -  | -    | -            | -    | \n",
    "| 4=positivo | -  | -    | -            | -    |\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db53ecd9-3004-4394-84ce-1b8c0ac9197f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e6b0eb-bfa5-445a-a048-708af3376fcc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(129783)\n",
    "np.random.seed(3213)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ba5b0-b53f-462b-b9c3-886faed5100f",
   "metadata": {},
   "source": [
    "# Importação\n",
    "\n",
    "Dados de origem: \n",
    "* http://help.sentiment140.com/for-students\n",
    "* colunas:\n",
    "   * sentiment (0=negativo, 2=neutro, 4=positivo)\n",
    "   * id\n",
    "   * date\n",
    "   * query_string\n",
    "   * user\n",
    "   * text\n",
    "\n",
    "Para este exercício:\n",
    "* apenas as colunas sentiment e text serão mantidas\n",
    "* sentimentos neutros serão descartados\n",
    "* sentimentos serão padronizados como 0=negativo e 1=positivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440c278b-5bef-4de3-a45c-af0a2de36e52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>0</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>0</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>0</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>0</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>0</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text\n",
       "0                1  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1                1  is upset that he can't update his Facebook by ...\n",
       "2                1  @Kenichan I dived many times for the ball. Man...\n",
       "3                1    my whole body feels itchy and like its on fire \n",
       "4                1  @nationwideclass no, it's not behaving at all....\n",
       "...            ...                                                ...\n",
       "1599995          0  Just woke up. Having no school is the best fee...\n",
       "1599996          0  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997          0  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998          0  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999          0  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bloco():\n",
    "    \n",
    "    global df_original\n",
    "    \n",
    "    df_cols = ['sentiment','id','date','query_string','user','text']\n",
    "\n",
    "    df_original = pd.read_csv(\n",
    "        \"training.1600000.processed.noemoticon.csv\",\n",
    "        header=None, \n",
    "        names=df_cols,\n",
    "        encoding = \"ISO-8859-1\"\n",
    "    )\n",
    "\n",
    "    df_original.drop(\n",
    "        ['id','date','query_string','user'],\n",
    "        axis=1,\n",
    "        inplace=True\n",
    "    )\n",
    "    df_original = df_original[ df_original['sentiment'] != 2 ] \n",
    "    df_original['sentiment'] = df_original['sentiment'].apply( lambda x: 1 if x==0 else 0 )\n",
    "    return df_original\n",
    "\n",
    "bloco()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ecf111-1a77-4ecf-95ec-e6fdebe3463c",
   "metadata": {},
   "source": [
    "# Padronização (1)\n",
    "\n",
    "* Parte 1\n",
    "  * remove todas as tags\n",
    "  * remove urls\n",
    "  * remove identificadores de usuários \n",
    "  * remove caracteres unicode inválidos\n",
    "  * remove carcteres não textuais\n",
    "  * transforma tudo para minúsculas\n",
    "* Parte 2\n",
    "  * tokeniza usando o keras\n",
    "* Parte 3\n",
    "  * separa base de treinamento e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa5df7e-ecbd-46c3-bdab-5e27c16cb0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text2</th>\n",
       "      <th>text3</th>\n",
       "      <th>text4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562641</th>\n",
       "      <td>1</td>\n",
       "      <td>Eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "      <td>eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "      <td>[636, 1907, 1, 77, 212, 113, 4, 71, 9, 228, 15...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596542</th>\n",
       "      <td>0</td>\n",
       "      <td>@SarY_ChaN</td>\n",
       "      <td>chan</td>\n",
       "      <td>[5851]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557121</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, the question as to whether I should get ...</td>\n",
       "      <td>well  the question as to whether i should get ...</td>\n",
       "      <td>[74, 3, 957, 83, 2, 2288, 1, 135, 36, 31, 25, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176192</th>\n",
       "      <td>0</td>\n",
       "      <td>Picnic in the sun</td>\n",
       "      <td>picnic in the sun</td>\n",
       "      <td>[2392, 10, 3, 275]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400171</th>\n",
       "      <td>0</td>\n",
       "      <td>Good morning! i'm outside and its a beautiful ...</td>\n",
       "      <td>good morning  i m outside and its a beautiful ...</td>\n",
       "      <td>[32, 95, 1, 20, 392, 7, 68, 4, 328, 33, 497, 5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092245</th>\n",
       "      <td>0</td>\n",
       "      <td>@smoochyfroggy You wellcome! Have a nice Day!</td>\n",
       "      <td>you wellcome  have a nice day</td>\n",
       "      <td>[8, 42399, 19, 4, 132, 33]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213310</th>\n",
       "      <td>1</td>\n",
       "      <td>Why is it so impossible to get an egg cream he...</td>\n",
       "      <td>why is it so impossible to get an egg cream he...</td>\n",
       "      <td>[110, 9, 6, 18, 2393, 2, 36, 93, 2444, 656, 86...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026205</th>\n",
       "      <td>0</td>\n",
       "      <td>lady at olive garden garden ask me if i cared ...</td>\n",
       "      <td>lady at olive garden garden ask me if i cared ...</td>\n",
       "      <td>[756, 25, 4727, 894, 894, 613, 17, 70, 1, 9128...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842287</th>\n",
       "      <td>0</td>\n",
       "      <td>Looking for domains. Great deals only.</td>\n",
       "      <td>looking for domains  great deals only</td>\n",
       "      <td>[209, 11, 10294, 99, 6290, 112]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292903</th>\n",
       "      <td>1</td>\n",
       "      <td>not wasting my money on a piercing that has a ...</td>\n",
       "      <td>not wasting my money on a piercing that has a ...</td>\n",
       "      <td>[26, 4254, 5, 414, 15, 4, 5087, 16, 100, 4, 10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137835</th>\n",
       "      <td>1</td>\n",
       "      <td>@rishil I think I'm the bigger geek as I found...</td>\n",
       "      <td>i think i m the bigger geek as i found that g...</td>\n",
       "      <td>[1, 77, 1, 20, 3, 2048, 2360, 83, 1, 320, 16, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468447</th>\n",
       "      <td>0</td>\n",
       "      <td>the only person who Jackson Rathbone (jasper) ...</td>\n",
       "      <td>the only person who jackson rathbone  jasper  ...</td>\n",
       "      <td>[3, 112, 536, 154, 3380, 23267, 8071, 116, 19,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692576</th>\n",
       "      <td>1</td>\n",
       "      <td>My Indian place is at farmer's market today!!!...</td>\n",
       "      <td>my indian place is at farmer s market today   ...</td>\n",
       "      <td>[5, 3174, 407, 9, 25, 6691, 12, 1713, 41, 21, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910387</th>\n",
       "      <td>0</td>\n",
       "      <td>@fancyfantastic you know I love you.</td>\n",
       "      <td>you know i love you</td>\n",
       "      <td>[8, 59, 1, 46, 8]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039469</th>\n",
       "      <td>0</td>\n",
       "      <td>don't want to go to work but i have to pay off...</td>\n",
       "      <td>don t want to go to work but i have to pay off...</td>\n",
       "      <td>[62, 14, 76, 2, 40, 2, 45, 21, 1, 19, 2, 564, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text  \\\n",
       "562641           1  Eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...   \n",
       "1596542          0                                      @SarY_ChaN      \n",
       "557121           1  Well, the question as to whether I should get ...   \n",
       "1176192          0                                 Picnic in the sun    \n",
       "1400171          0  Good morning! i'm outside and its a beautiful ...   \n",
       "1092245          0     @smoochyfroggy You wellcome! Have a nice Day!    \n",
       "213310           1  Why is it so impossible to get an egg cream he...   \n",
       "1026205          0  lady at olive garden garden ask me if i cared ...   \n",
       "842287           0            Looking for domains. Great deals only.    \n",
       "292903           1  not wasting my money on a piercing that has a ...   \n",
       "137835           1  @rishil I think I'm the bigger geek as I found...   \n",
       "1468447          0  the only person who Jackson Rathbone (jasper) ...   \n",
       "692576           1  My Indian place is at farmer's market today!!!...   \n",
       "910387           0              @fancyfantastic you know I love you.    \n",
       "1039469          0  don't want to go to work but i have to pay off...   \n",
       "\n",
       "                                                     text2  \\\n",
       "562641   eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...   \n",
       "1596542                                            chan      \n",
       "557121   well  the question as to whether i should get ...   \n",
       "1176192                                 picnic in the sun    \n",
       "1400171  good morning  i m outside and its a beautiful ...   \n",
       "1092245                    you wellcome  have a nice day     \n",
       "213310   why is it so impossible to get an egg cream he...   \n",
       "1026205  lady at olive garden garden ask me if i cared ...   \n",
       "842287             looking for domains  great deals only     \n",
       "292903   not wasting my money on a piercing that has a ...   \n",
       "137835    i think i m the bigger geek as i found that g...   \n",
       "1468447  the only person who jackson rathbone  jasper  ...   \n",
       "692576   my indian place is at farmer s market today   ...   \n",
       "910387                               you know i love you     \n",
       "1039469  don t want to go to work but i have to pay off...   \n",
       "\n",
       "                                                     text3  \\\n",
       "562641   [636, 1907, 1, 77, 212, 113, 4, 71, 9, 228, 15...   \n",
       "1596542                                             [5851]   \n",
       "557121   [74, 3, 957, 83, 2, 2288, 1, 135, 36, 31, 25, ...   \n",
       "1176192                                 [2392, 10, 3, 275]   \n",
       "1400171  [32, 95, 1, 20, 392, 7, 68, 4, 328, 33, 497, 5...   \n",
       "1092245                         [8, 42399, 19, 4, 132, 33]   \n",
       "213310   [110, 9, 6, 18, 2393, 2, 36, 93, 2444, 656, 86...   \n",
       "1026205  [756, 25, 4727, 894, 894, 613, 17, 70, 1, 9128...   \n",
       "842287                     [209, 11, 10294, 99, 6290, 112]   \n",
       "292903   [26, 4254, 5, 414, 15, 4, 5087, 16, 100, 4, 10...   \n",
       "137835   [1, 77, 1, 20, 3, 2048, 2360, 83, 1, 320, 16, ...   \n",
       "1468447  [3, 112, 536, 154, 3380, 23267, 8071, 116, 19,...   \n",
       "692576   [5, 3174, 407, 9, 25, 6691, 12, 1713, 41, 21, ...   \n",
       "910387                                   [8, 59, 1, 46, 8]   \n",
       "1039469  [62, 14, 76, 2, 40, 2, 45, 21, 1, 19, 2, 564, ...   \n",
       "\n",
       "                                                     text4  \n",
       "562641   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1596542  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "557121   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1176192  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1400171  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1092245  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "213310   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1026205  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "842287   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "292903   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "137835   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1468447  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "692576   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "910387   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1039469  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_limit = 200000\n",
    "max_words = 100000\n",
    "max_len = 1000\n",
    "\n",
    "def bloco():\n",
    "    \n",
    "    global df_original\n",
    "    global df_train\n",
    "    global df_test   \n",
    "   \n",
    "    # PARTE 1 - Limpa o texto \n",
    "    import re\n",
    "    pat1 = r'@[A-Za-z0-9]+'\n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "    pat3 = r'<.*?>'\n",
    "    pat4 = r'&.*?;'\n",
    "    pat = r'|'.join((pat1, pat2, pat3, pat4))\n",
    "    def tweet_cleaner(text):       \n",
    "        text = re.sub(pat,'',text)\n",
    "        try:\n",
    "            text = text.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "        except:\n",
    "            text = text\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "        text = text.lower()\n",
    "        return text\n",
    "\n",
    "    df_original['text2'] = df_original['text'].apply( tweet_cleaner )\n",
    "\n",
    "    \n",
    "    # PARTE 2 - Tokeniza usando o Keras\n",
    "    global tokenizer\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words,lower=True, split=\" \")\n",
    "    tokenizer.fit_on_texts(df_original['text2'])\n",
    "    #df_original['text3'] = tokenizer.texts_to_sequences(df_original['text2'])\n",
    "    #df_original['text4'] = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    #    df_original['text3'], \n",
    "    #    maxlen=max_len,\n",
    "    #    #padding='post',\n",
    "    #    #truncating='post'        \n",
    "    #).tolist()                                                                                                   \n",
    "   \n",
    "\n",
    "    global df_example\n",
    "    df_example = df_original.sample(15)\n",
    "    df_example['text3'] = tokenizer.texts_to_sequences(df_example['text2'])\n",
    "    df_example['text4'] = tf.keras.preprocessing.sequence.pad_sequences( df_example['text3'], maxlen=max_len ).tolist()              \n",
    "        \n",
    "    # PARTE 3 - Separa amostra de treinamento e de teste\n",
    "   \n",
    "    # 1 = train | 0 = test\n",
    "    df_original['rand'] = pd.Series([0,1]).sample(len(df_original), replace=True).array\n",
    "    \n",
    "    df_train_sz = 10000\n",
    "    df_train = df_original[ df_original[ 'rand' ] == 1 ]\n",
    "    df_train_positive = df_train[ df_train['sentiment'] == 0 ].sample(n=int(df_train_sz/2), replace=True)\n",
    "    df_train_negative = df_train[ df_train['sentiment'] == 1 ].sample(n=int(df_train_sz/2), replace=True)\n",
    "    df_train = pd.concat( [ df_train_negative, df_train_positive ] )    \n",
    "    df_train = df_train.sample(frac=1.0).reset_index(drop=True)\n",
    "    \n",
    "    df_test_sz = 40000\n",
    "    df_test = df_original[ df_original[ 'rand' ] == 0 ].sample(int(df_test_sz/2), replace=True)\n",
    "    df_test = df_test.sample(frac=1.0).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "bloco()\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07e57a-8455-4496-b901-75bf0a9c7a3a",
   "metadata": {},
   "source": [
    "Na tabela acima é possível ver os estagios da limpeza:\n",
    "* **text** contém o texto original da base \n",
    "* **text2** contém o texto após limpeza de tags, urls, nomes de usuário, números e minusculas\n",
    "* **text3** contém o texto codificado em \"embeddings\" pelo tensorflow. Cada palavra foi convertida em um número. \n",
    "* **text4** contém o texto codificado em \"embeddings\" com o padding. Só aparecem zeros aqui pois uma coluna com 1,2,3 em text3 será codificada como 0,0,0,0[...],1,2,3. Como é raro encontrar um tweet com mais de 180 palavras, o início é quase sempre [0,0,0,0,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287581a-38e5-450c-9d8f-ba1c83f12161",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4370bdf-cc7d-4c11-8c86-a689cddb5c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()         \n",
    "model.add(tf.keras.layers.Embedding(max_words, 100, mask_zero=True))\n",
    "model.add(tf.keras.layers.LSTM(32))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10907d22-fe7b-42f4-9113-8ef5c0b141e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 100)         10000000  \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                17024     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,018,625\n",
      "Trainable params: 10,018,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "model.compile(\n",
    "    #optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001,momentum=0.5),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\n",
    "        'acc',        \n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tfa.metrics.F1Score(num_classes=1, threshold=0.5, name='f1')\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0ffe26f-d9f7-4695-91b1-08d14b2b2971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(10000, 1000) y.shape=(10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences( tokenizer.texts_to_sequences( df_train['text2'] ), maxlen=max_len )\n",
    "y_train = df_train['sentiment'].values\n",
    "\n",
    "print( f'X.shape={X_train.shape} y.shape={y_train.shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bf989e9-9000-43ea-b2da-efec2943078e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "27/27 [==============================] - 42s 1s/step - loss: 0.6931 - acc: 0.5020 - prec: 0.5023 - recall: 0.7739 - f1: 0.6092 - val_loss: 0.6932 - val_acc: 0.4945 - val_prec: 0.4933 - val_recall: 0.8623 - val_f1: 0.6276 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "27/27 [==============================] - 41s 2s/step - loss: 0.6929 - acc: 0.5136 - prec: 0.5095 - recall: 0.8081 - f1: 0.6250 - val_loss: 0.6930 - val_acc: 0.5040 - val_prec: 0.4989 - val_recall: 0.8907 - val_f1: 0.6395 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "27/27 [==============================] - 44s 2s/step - loss: 0.6926 - acc: 0.5154 - prec: 0.5105 - recall: 0.8213 - f1: 0.6296 - val_loss: 0.6928 - val_acc: 0.5135 - val_prec: 0.5042 - val_recall: 0.9038 - val_f1: 0.6473 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "27/27 [==============================] - 39s 1s/step - loss: 0.6925 - acc: 0.5131 - prec: 0.5090 - recall: 0.8240 - f1: 0.6293 - val_loss: 0.6926 - val_acc: 0.5235 - val_prec: 0.5098 - val_recall: 0.9251 - val_f1: 0.6573 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "27/27 [==============================] - 41s 2s/step - loss: 0.6921 - acc: 0.5281 - prec: 0.5178 - recall: 0.8582 - f1: 0.6459 - val_loss: 0.6922 - val_acc: 0.5245 - val_prec: 0.5101 - val_recall: 0.9494 - val_f1: 0.6636 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "27/27 [==============================] - 39s 1s/step - loss: 0.6917 - acc: 0.5247 - prec: 0.5158 - recall: 0.8539 - f1: 0.6431 - val_loss: 0.6917 - val_acc: 0.5330 - val_prec: 0.5148 - val_recall: 0.9534 - val_f1: 0.6686 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "27/27 [==============================] - 39s 1s/step - loss: 0.6910 - acc: 0.5406 - prec: 0.5249 - recall: 0.8868 - f1: 0.6594 - val_loss: 0.6911 - val_acc: 0.5460 - val_prec: 0.5225 - val_recall: 0.9413 - val_f1: 0.6720 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "27/27 [==============================] - 41s 2s/step - loss: 0.6902 - acc: 0.5541 - prec: 0.5344 - recall: 0.8627 - f1: 0.6599 - val_loss: 0.6903 - val_acc: 0.5570 - val_prec: 0.5301 - val_recall: 0.9089 - val_f1: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.6891 - acc: 0.5635 - prec: 0.5410 - recall: 0.8544 - f1: 0.6625 - val_loss: 0.6892 - val_acc: 0.5695 - val_prec: 0.5382 - val_recall: 0.9059 - val_f1: 0.6752 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.6883 - acc: 0.5667 - prec: 0.5447 - recall: 0.8295 - f1: 0.6576 - val_loss: 0.6878 - val_acc: 0.5815 - val_prec: 0.5460 - val_recall: 0.9079 - val_f1: 0.6819 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "27/27 [==============================] - 43s 2s/step - loss: 0.6863 - acc: 0.5906 - prec: 0.5611 - recall: 0.8440 - f1: 0.6740 - val_loss: 0.6860 - val_acc: 0.5815 - val_prec: 0.5455 - val_recall: 0.9160 - val_f1: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "27/27 [==============================] - 41s 2s/step - loss: 0.6842 - acc: 0.5941 - prec: 0.5626 - recall: 0.8572 - f1: 0.6793 - val_loss: 0.6837 - val_acc: 0.6050 - val_prec: 0.5632 - val_recall: 0.8927 - val_f1: 0.6907 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "27/27 [==============================] - 39s 1s/step - loss: 0.6814 - acc: 0.6143 - prec: 0.5778 - recall: 0.8569 - f1: 0.6902 - val_loss: 0.6808 - val_acc: 0.6220 - val_prec: 0.5759 - val_recall: 0.8907 - val_f1: 0.6995 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "27/27 [==============================] - 40s 2s/step - loss: 0.6781 - acc: 0.6227 - prec: 0.5865 - recall: 0.8397 - f1: 0.6907 - val_loss: 0.6771 - val_acc: 0.6365 - val_prec: 0.5886 - val_recall: 0.8775 - val_f1: 0.7046 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.6736 - acc: 0.6324 - prec: 0.5960 - recall: 0.8285 - f1: 0.6933 - val_loss: 0.6727 - val_acc: 0.6490 - val_prec: 0.6001 - val_recall: 0.8674 - val_f1: 0.7094 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.6684 - acc: 0.6475 - prec: 0.6099 - recall: 0.8243 - f1: 0.7011 - val_loss: 0.6674 - val_acc: 0.6505 - val_prec: 0.6020 - val_recall: 0.8634 - val_f1: 0.7094 - lr: 1.0000e-04\n",
      "Epoch 17/30\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.6622 - acc: 0.6641 - prec: 0.6244 - recall: 0.8290 - f1: 0.7123 - val_loss: 0.6611 - val_acc: 0.6600 - val_prec: 0.6148 - val_recall: 0.8350 - val_f1: 0.7082 - lr: 1.0000e-04\n",
      "Epoch 18/30\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.6550 - acc: 0.6694 - prec: 0.6315 - recall: 0.8183 - f1: 0.7128 - val_loss: 0.6544 - val_acc: 0.6725 - val_prec: 0.6342 - val_recall: 0.7966 - val_f1: 0.7061 - lr: 1.0000e-04\n",
      "Epoch 19/30\n",
      "27/27 [==============================] - 49s 2s/step - loss: 0.6465 - acc: 0.6914 - prec: 0.6550 - recall: 0.8126 - f1: 0.7253 - val_loss: 0.6466 - val_acc: 0.6740 - val_prec: 0.6340 - val_recall: 0.8047 - val_f1: 0.7092 - lr: 1.0000e-04\n",
      "Epoch 20/30\n",
      "27/27 [==============================] - 54s 2s/step - loss: 0.6375 - acc: 0.6973 - prec: 0.6675 - recall: 0.7896 - f1: 0.7235 - val_loss: 0.6386 - val_acc: 0.6805 - val_prec: 0.6397 - val_recall: 0.8087 - val_f1: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 21/30\n",
      "27/27 [==============================] - 50s 2s/step - loss: 0.6258 - acc: 0.7049 - prec: 0.6727 - recall: 0.8016 - f1: 0.7315 - val_loss: 0.6304 - val_acc: 0.6910 - val_prec: 0.6557 - val_recall: 0.7885 - val_f1: 0.7160 - lr: 1.0000e-04\n",
      "Epoch 22/30\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.6152 - acc: 0.7186 - prec: 0.6937 - recall: 0.7859 - f1: 0.7369 - val_loss: 0.6219 - val_acc: 0.7040 - val_prec: 0.6800 - val_recall: 0.7571 - val_f1: 0.7165 - lr: 1.0000e-04\n",
      "Epoch 23/30\n",
      "27/27 [==============================] - 43s 2s/step - loss: 0.6064 - acc: 0.7275 - prec: 0.7103 - recall: 0.7712 - f1: 0.7395 - val_loss: 0.6143 - val_acc: 0.7065 - val_prec: 0.6845 - val_recall: 0.7530 - val_f1: 0.7171 - lr: 1.0000e-04\n",
      "Epoch 24/30\n",
      "27/27 [==============================] - 42s 2s/step - loss: 0.5940 - acc: 0.7375 - prec: 0.7259 - recall: 0.7657 - f1: 0.7453 - val_loss: 0.6073 - val_acc: 0.7125 - val_prec: 0.6889 - val_recall: 0.7621 - val_f1: 0.7237 - lr: 1.0000e-04\n",
      "Epoch 25/30\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.5844 - acc: 0.7454 - prec: 0.7373 - recall: 0.7647 - f1: 0.7508 - val_loss: 0.6007 - val_acc: 0.7185 - val_prec: 0.7007 - val_recall: 0.7510 - val_f1: 0.7250 - lr: 1.0000e-04\n",
      "Epoch 26/30\n",
      "27/27 [==============================] - 40s 1s/step - loss: 0.5712 - acc: 0.7545 - prec: 0.7521 - recall: 0.7615 - f1: 0.7568 - val_loss: 0.5947 - val_acc: 0.7225 - val_prec: 0.7068 - val_recall: 0.7490 - val_f1: 0.7273 - lr: 1.0000e-04\n",
      "Epoch 27/30\n",
      "27/27 [==============================] - 41s 2s/step - loss: 0.5623 - acc: 0.7615 - prec: 0.7578 - recall: 0.7707 - f1: 0.7642 - val_loss: 0.5891 - val_acc: 0.7280 - val_prec: 0.7202 - val_recall: 0.7348 - val_f1: 0.7275 - lr: 1.0000e-04\n",
      "Epoch 28/30\n",
      "27/27 [==============================] - 42s 2s/step - loss: 0.5531 - acc: 0.7703 - prec: 0.7727 - recall: 0.7677 - f1: 0.7702 - val_loss: 0.5847 - val_acc: 0.7245 - val_prec: 0.7099 - val_recall: 0.7480 - val_f1: 0.7284 - lr: 1.0000e-04\n",
      "Epoch 29/30\n",
      "27/27 [==============================] - 48s 2s/step - loss: 0.5421 - acc: 0.7746 - prec: 0.7750 - recall: 0.7759 - f1: 0.7754 - val_loss: 0.5801 - val_acc: 0.7305 - val_prec: 0.7216 - val_recall: 0.7399 - val_f1: 0.7306 - lr: 1.0000e-04\n",
      "Epoch 30/30\n",
      "27/27 [==============================] - 57s 2s/step - loss: 0.5305 - acc: 0.7871 - prec: 0.7934 - recall: 0.7782 - f1: 0.7857 - val_loss: 0.5765 - val_acc: 0.7275 - val_prec: 0.7187 - val_recall: 0.7368 - val_f1: 0.7276 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "my_callbacks = [\n",
    "        # abandona o processamento se a acurácia não melhorar em até {patitence} épocas\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_acc',patience=6), \n",
    "        # grava os modelos intermediários\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath='model/model.{epoch:02d}.h5'), # salva o modelo para poder retomar o treinamento\n",
    "        # grava informações para visualização\n",
    "        # tf.keras.callbacks.TensorBoard(log_dir='./logs'), \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, min_lr=0.00001)\n",
    "    ]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    batch_size=300,\n",
    "    validation_split=0.20,\n",
    "    callbacks=my_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2887c40d-84c0-488f-b08d-084725b5c7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bloco():\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, ax = plt.subplots(2,1,figsize=(16,6))\n",
    "    ax[0].plot(history.history['val_loss'], color='#FF0000', label=\"val_loss\")\n",
    "    ax[0].plot(history.history['loss'], color='#FFA0A0', label=\"loss\")\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "        \n",
    "    ax[1].plot(history.history['val_acc'], color='#00FF00', label=\"val_acc\")\n",
    "    ax[1].plot(history.history['acc'], color='#A0FFA0', label=\"acc\")\n",
    "    ax[1].set_ylim([0.0,1.0])\n",
    "    legend = ax[1].legend(loc='best', shadow=True)        \n",
    "    \n",
    "bloco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bd4c54d-1b75-4714-9a57-82a966522e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 51s 3s/step - loss: 0.5211 - acc: 0.7944 - prec: 0.7958 - recall: 0.7939 - f1: 0.7949 - val_loss: 0.5272 - val_acc: 0.7768 - val_prec: 0.7776 - val_recall: 0.7732 - val_f1: 0.7754 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.5100 - acc: 0.8012 - prec: 0.8051 - recall: 0.7967 - f1: 0.8009 - val_loss: 0.5241 - val_acc: 0.7792 - val_prec: 0.7850 - val_recall: 0.7668 - val_f1: 0.7758 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.5002 - acc: 0.8052 - prec: 0.8126 - recall: 0.7951 - f1: 0.8038 - val_loss: 0.5221 - val_acc: 0.7772 - val_prec: 0.7800 - val_recall: 0.7700 - val_f1: 0.7749 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.4967 - acc: 0.8070 - prec: 0.8164 - recall: 0.7939 - f1: 0.8050 - val_loss: 0.5211 - val_acc: 0.7736 - val_prec: 0.7676 - val_recall: 0.7824 - val_f1: 0.7750 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 51s 3s/step - loss: 0.4865 - acc: 0.8166 - prec: 0.8228 - recall: 0.8087 - f1: 0.8157 - val_loss: 0.5180 - val_acc: 0.7782 - val_prec: 0.7830 - val_recall: 0.7676 - val_f1: 0.7752 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 52s 3s/step - loss: 0.4771 - acc: 0.8216 - prec: 0.8291 - recall: 0.8119 - f1: 0.8204 - val_loss: 0.5163 - val_acc: 0.7760 - val_prec: 0.7841 - val_recall: 0.7595 - val_f1: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 59s 4s/step - loss: 0.4665 - acc: 0.8284 - prec: 0.8401 - recall: 0.8127 - f1: 0.8262 - val_loss: 0.5157 - val_acc: 0.7788 - val_prec: 0.7800 - val_recall: 0.7744 - val_f1: 0.7772 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 65s 4s/step - loss: 0.4593 - acc: 0.8350 - prec: 0.8520 - recall: 0.8123 - f1: 0.8317 - val_loss: 0.5180 - val_acc: 0.7730 - val_prec: 0.7622 - val_recall: 0.7912 - val_f1: 0.7764 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    batch_size=300,\n",
    "    validation_split=0.50,\n",
    "    callbacks=my_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5fc9b1-b997-4b00-9dc1-d7883d0d4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloco():\n",
    "    \n",
    "    print( 'Seleciona o modelo com maior acurácia durante a validação (usualmente antes do overfit)' )\n",
    "    \n",
    "    best_acc = max(history.history['val_acc'])\n",
    "    best_epoch = history.history['val_acc'].index(best_acc) + 1\n",
    "    \n",
    "    print( f'melhor epoca: {best_epoch} val_acc={best_acc:1.2f}' )    \n",
    "        \n",
    "    model.load_weights( f'model/model.{best_epoch:02d}.h5' )\n",
    "\n",
    "bloco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3082774-9c0e-4bc3-ab29-e2264ff2f4da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 144s 231ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi guys!  I have been dying to Tweet you.........</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watching the MTV awards wishing i was cool eno...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going to shop with my BFF today, it's gonn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alot of new pictures tweets  ; some really old...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scariest words ever, &amp;quot;Mommy, I cant breat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>ahhh Time to relax babies are in bed.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>@NarelleKylie I missed you  boohoo!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>I still cann't vote on Mr twitter. The &amp;quot;+...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>it is so hot that i am totally melting now</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>My boy came home with food.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  predicted\n",
       "0      Hi guys!  I have been dying to Tweet you.........          0          0\n",
       "1      watching the MTV awards wishing i was cool eno...          1          0\n",
       "2      I'm going to shop with my BFF today, it's gonn...          0          0\n",
       "3      alot of new pictures tweets  ; some really old...          0          0\n",
       "4      Scariest words ever, &quot;Mommy, I cant breat...          1          1\n",
       "...                                                  ...        ...        ...\n",
       "19995             ahhh Time to relax babies are in bed.           0          0\n",
       "19996                @NarelleKylie I missed you  boohoo!          1          1\n",
       "19997  I still cann't vote on Mr twitter. The &quot;+...          1          1\n",
       "19998       it is so hot that i am totally melting now            1          1\n",
       "19999                       My boy came home with food.           0          1\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tf.keras.preprocessing.sequence.pad_sequences( tokenizer.texts_to_sequences( df_test['text2'] ), maxlen=max_len )\n",
    "y_test = df_test['sentiment'].values\n",
    "y_pred = [ 1 if y_pred > 0.5 else 0 for y_pred in model.predict(X_test).reshape(len(X_test)) ]\n",
    "\n",
    "df_test['predicted'] = y_pred\n",
    "df_test[ ['text','sentiment','predicted'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b78808-bba4-4c29-ba9b-41103ea63cc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "        <style>\n",
       "           .luc_confusion_mtx td { background: white!IMPORTANT; border: 0pt !IMPORTANT; text-align: center!IMPORTANT }           \n",
       "           td.luc_confusion_mtx_dp { width: 90pt; height: 90pt; background: #c0ffc0!IMPORTANT; border: 1pt solid black!IMPORTANT } \n",
       "           td.luc_confusion_mtx_dn { width: 90pt; height: 90pt; background: #ffc0c0!IMPORTANT; border: 1pt solid black!IMPORTANT }            \n",
       "        </style>\n",
       "        \n",
       "               \n",
       "        <table class='luc_confusion_mtx'>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td colspan=2>Previsão</td>\n",
       "            <td></td>\n",
       "            <td rowspan=5 style='text-align: left!IMPORTANT'>\n",
       "                    Acurácia<br><big><big>(TP+TN)/(total)</big></big> = 14631/20000 = <big>73.2%</big><br>\n",
       "                    <br><br>\n",
       "                    Considerando que as duas classes (0=sentimento negativo;1=sentimento positivo) tem igual \n",
       "                    valor para esta análise, é importante maximizar a diagonal verde / minimizar a diagonal vermelha,\n",
       "                    portanto os indicadores de Acurácia OU F1 são os mais indicados.<br>\n",
       "                    <br>\n",
       "                    Os indicadores de precisão e sensibilidade(recall) podem ser usados em conjunto, mas não são\n",
       "                    muito intuitivos para este conjunto de dados pois mensuram da perspectiva do \"sentimento positivo\".\n",
       "                    Em outras palavras, a sensibilidade indica quantos \"sentimentos positivos\" corretos foram encontrados\n",
       "                    e a \"precisão\" indica do total apontado pelo modelo como \"sentimento positivo\", quantos eram. \n",
       "            </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td>Negativo</td>\n",
       "            <td>Positivo</td>\n",
       "            <td></td>            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td rowspan=2>Real</td>\n",
       "            <td>Negativo</td>\n",
       "            <td class=\"luc_confusion_mtx_dp\"><big><big>TN</big></big><br>7048<br>35.2%</td>\n",
       "            <td class=\"luc_confusion_mtx_dn\"><big><big>FP</big></big><br>2845<br>14.2%</td>\n",
       "            <td>9893</td>\n",
       "        </tr>        \n",
       "        <tr>\n",
       "            <td>Positivo</td>\n",
       "            <td class=\"luc_confusion_mtx_dn\"><big><big>FN</big></big><br>2524<br>12.6%</td>\n",
       "            <td class=\"luc_confusion_mtx_dp\"><big><big>TP</big></big><br>7583<br>37.9%</td>\n",
       "            <td>5369</td>\n",
       "        </tr>  \n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td>9572</td>\n",
       "            <td>10428</td>\n",
       "            <td>20000</td>\n",
       "        </tr>  \n",
       "        </table>    \n",
       "        \n",
       "        \n",
       "       \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Acurácia=73.16% dos apontamentos positivos e negativos estão corretos\n",
      " Recall/Sensibilidade=75.03% dos sentimentos positivos da base foram apontados\n",
      "             Precisão=72.72% dos sentimentos positivos apontados estão corretos\n",
      "             F1 Score=74.08% média harmônica da acurácia e recall\n"
     ]
    }
   ],
   "source": [
    "def block():\n",
    "    \n",
    "    global confusion_mtx\n",
    "    global confusion_mtx_pc\n",
    "    \n",
    "    confusion_mtx = tf.math.confusion_matrix( y_test, y_pred )\n",
    "\n",
    "    confusion_mtx = pd.DataFrame( confusion_mtx )\n",
    "    confusion_mtx.loc['Total'] = confusion_mtx.sum(numeric_only=True) \n",
    "    confusion_mtx['total'] = confusion_mtx[0] + confusion_mtx[1]\n",
    "    \n",
    "    confusion_mtx_pc = confusion_mtx / len(y_test)\n",
    "    \n",
    "    fp = confusion_mtx.iloc[0,1] \n",
    "    fn = confusion_mtx.iloc[1,0]\n",
    "    tn = confusion_mtx.iloc[0,0]\n",
    "    tp = confusion_mtx.iloc[1,1] \n",
    "    \n",
    "    total = (tp+tn+fp+fn)\n",
    "    \n",
    "    acc       = (tp+tn)/(tp+tn+fp+fn)\n",
    "    recall    = tp/(tp+fn)\n",
    "    f1        = (2*acc*recall)/(acc+recall)\n",
    "    \n",
    "    fdr  = fp/(fp+tp)\n",
    "    fnr  = fn/(fn+tp)\n",
    "    \n",
    "    tpr = tp/(fn+tp)\n",
    "    ppv  = tp/(fp+tp)\n",
    "    \n",
    "    \n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(f\"\"\"\n",
    "    \n",
    "        <style>\n",
    "           .luc_confusion_mtx td {{ background: white!IMPORTANT; border: 0pt !IMPORTANT; text-align: center!IMPORTANT }}           \n",
    "           td.luc_confusion_mtx_dp {{ width: 90pt; height: 90pt; background: #c0ffc0!IMPORTANT; border: 1pt solid black!IMPORTANT }} \n",
    "           td.luc_confusion_mtx_dn {{ width: 90pt; height: 90pt; background: #ffc0c0!IMPORTANT; border: 1pt solid black!IMPORTANT }}            \n",
    "        </style>\n",
    "        \n",
    "               \n",
    "        <table class='luc_confusion_mtx'>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td colspan=2>Previsão</td>\n",
    "            <td></td>\n",
    "            <td rowspan=5 style='text-align: left!IMPORTANT'>\n",
    "                    Acurácia<br><big><big>(TP+TN)/(total)</big></big> = {tp+tn}/{total} = <big>{(tp+tn)*100.0/total:2.1f}%</big><br>\n",
    "                    <br><br>\n",
    "                    Considerando que as duas classes (0=sentimento negativo;1=sentimento positivo) tem igual \n",
    "                    valor para esta análise, é importante maximizar a diagonal verde / minimizar a diagonal vermelha,\n",
    "                    portanto os indicadores de Acurácia OU F1 são os mais indicados.<br>\n",
    "                    <br>\n",
    "                    Os indicadores de precisão e sensibilidade(recall) podem ser usados em conjunto, mas não são\n",
    "                    muito intuitivos para este conjunto de dados pois mensuram da perspectiva do \"sentimento positivo\".\n",
    "                    Em outras palavras, a sensibilidade indica quantos \"sentimentos positivos\" corretos foram encontrados\n",
    "                    e a \"precisão\" indica do total apontado pelo modelo como \"sentimento positivo\", quantos eram. \n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>Negativo</td>\n",
    "            <td>Positivo</td>\n",
    "            <td></td>            \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=2>Real</td>\n",
    "            <td>Negativo</td>\n",
    "            <td class=\"luc_confusion_mtx_dp\"><big><big>TN</big></big><br>{tn}<br>{tn*100.0/total:2.1f}%</td>\n",
    "            <td class=\"luc_confusion_mtx_dn\"><big><big>FP</big></big><br>{fp}<br>{fp*100.0/total:2.1f}%</td>\n",
    "            <td>{tn+fp}</td>\n",
    "        </tr>        \n",
    "        <tr>\n",
    "            <td>Positivo</td>\n",
    "            <td class=\"luc_confusion_mtx_dn\"><big><big>FN</big></big><br>{fn}<br>{fn*100.0/total:2.1f}%</td>\n",
    "            <td class=\"luc_confusion_mtx_dp\"><big><big>TP</big></big><br>{tp}<br>{tp*100.0/total:2.1f}%</td>\n",
    "            <td>{fn+fp}</td>\n",
    "        </tr>  \n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>{tn+fn}</td>\n",
    "            <td>{fp+tp}</td>\n",
    "            <td>{total}</td>\n",
    "        </tr>  \n",
    "        </table>    \n",
    "        \n",
    "        \n",
    "       \n",
    "    \"\"\"))        \n",
    "    \n",
    "    print( f'             Acurácia={acc*100.0:05.2f}% dos apontamentos positivos e negativos estão corretos' )\n",
    "    print( f' Recall/Sensibilidade={tpr*100.0:05.2f}% dos sentimentos positivos da base foram apontados' )   \n",
    "    print( f'             Precisão={ppv*100.0:05.2f}% dos sentimentos positivos apontados estão corretos' )    \n",
    "    print( f'             F1 Score={f1*100.0:05.2f}% média harmônica da acurácia e recall' )        \n",
    "      \n",
    "\n",
    "    \n",
    "block()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b8407-9462-4823-9496-e6da6f55d6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "venv_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
