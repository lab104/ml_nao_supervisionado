{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4375a019-4937-415a-bbea-5f425534a693",
   "metadata": {},
   "source": [
    "# Instituto de Educação Superior de Brası́lia – IESB\n",
    "## Pós-Graduação em Inteligência Artificial\n",
    "### Disciplina de Computação Cognitiva 3 / Turma 2021-1\n",
    "#### Trabalho Final - Análise de Sentimento\n",
    "\n",
    "                          EQUIPE:\n",
    "                          - LUCAS DE SOUSA BRITO, MAT:2186330019, TURMA: 2021-1\n",
    "                          - PABLO NOGUEIRA OLIVEIRA, MAT:2186330027, TURMA: 2021-1\n",
    "                          - MATHEUS BARBOSA OLIVEIRA, MAT:2186330037, TURMA: 2021-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c69181-56d4-458d-bf05-9afd6d160fbf",
   "metadata": {},
   "source": [
    "# Análise de sentimento da base do twitter Sentiment140\n",
    "\n",
    "### Dados de Origem\n",
    "\n",
    "* http://help.sentiment140.com/for-students\n",
    "\n",
    "| sentiment  | id | date | query_string | user | text\n",
    "| ---        | -- | -    | -            | -    | ---\n",
    "| 0=negativo | -  | -    | -            | -    | the original twitter message\n",
    "| 2=neutro   | -  | -    | -            | -    | \n",
    "| 4=positivo | -  | -    | -            | -    |\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db53ecd9-3004-4394-84ce-1b8c0ac9197f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e6b0eb-bfa5-445a-a048-708af3376fcc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(129783)\n",
    "np.random.seed(3213)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ba5b0-b53f-462b-b9c3-886faed5100f",
   "metadata": {},
   "source": [
    "# Importação\n",
    "\n",
    "Dados de origem: \n",
    "* http://help.sentiment140.com/for-students\n",
    "* colunas:\n",
    "   * sentiment (0=negativo, 2=neutro, 4=positivo)\n",
    "   * id\n",
    "   * date\n",
    "   * query_string\n",
    "   * user\n",
    "   * text\n",
    "\n",
    "Para este exercício:\n",
    "* apenas as colunas sentiment e text serão mantidas\n",
    "* sentimentos neutros serão descartados\n",
    "* sentimentos serão padronizados como 0=negativo e 1=positivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440c278b-5bef-4de3-a45c-af0a2de36e52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>0</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>0</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>0</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>0</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>0</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text\n",
       "0                1  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1                1  is upset that he can't update his Facebook by ...\n",
       "2                1  @Kenichan I dived many times for the ball. Man...\n",
       "3                1    my whole body feels itchy and like its on fire \n",
       "4                1  @nationwideclass no, it's not behaving at all....\n",
       "...            ...                                                ...\n",
       "1599995          0  Just woke up. Having no school is the best fee...\n",
       "1599996          0  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997          0  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998          0  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999          0  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bloco():\n",
    "    \n",
    "    global df_original\n",
    "    \n",
    "    df_cols = ['sentiment','id','date','query_string','user','text']\n",
    "\n",
    "    df_original = pd.read_csv(\n",
    "        \"training.1600000.processed.noemoticon.csv\",\n",
    "        header=None, \n",
    "        names=df_cols,\n",
    "        encoding = \"ISO-8859-1\"\n",
    "    )\n",
    "\n",
    "    df_original.drop(\n",
    "        ['id','date','query_string','user'],\n",
    "        axis=1,\n",
    "        inplace=True\n",
    "    )\n",
    "    df_original = df_original[ df_original['sentiment'] != 2 ] \n",
    "    df_original['sentiment'] = df_original['sentiment'].apply( lambda x: 1 if x==0 else 0 )\n",
    "    return df_original\n",
    "\n",
    "bloco()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ecf111-1a77-4ecf-95ec-e6fdebe3463c",
   "metadata": {},
   "source": [
    "# Padronização (1)\n",
    "\n",
    "* Parte 1\n",
    "  * remove todas as tags\n",
    "  * remove urls\n",
    "  * remove identificadores de usuários \n",
    "  * remove caracteres unicode inválidos\n",
    "  * remove carcteres não textuais\n",
    "  * transforma tudo para minúsculas\n",
    "* Parte 2\n",
    "  * tokeniza usando o keras\n",
    "* Parte 3\n",
    "  * separa base de treinamento e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa5df7e-ecbd-46c3-bdab-5e27c16cb0f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text2</th>\n",
       "      <th>text3</th>\n",
       "      <th>text4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562641</th>\n",
       "      <td>1</td>\n",
       "      <td>Eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "      <td>eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "      <td>[636, 1907, 1, 77, 212, 113, 4, 71, 9, 228, 15...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596542</th>\n",
       "      <td>0</td>\n",
       "      <td>@SarY_ChaN</td>\n",
       "      <td>chan</td>\n",
       "      <td>[5851]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557121</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, the question as to whether I should get ...</td>\n",
       "      <td>well  the question as to whether i should get ...</td>\n",
       "      <td>[74, 3, 957, 83, 2, 2288, 1, 135, 36, 31, 25, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176192</th>\n",
       "      <td>0</td>\n",
       "      <td>Picnic in the sun</td>\n",
       "      <td>picnic in the sun</td>\n",
       "      <td>[2392, 10, 3, 275]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400171</th>\n",
       "      <td>0</td>\n",
       "      <td>Good morning! i'm outside and its a beautiful ...</td>\n",
       "      <td>good morning  i m outside and its a beautiful ...</td>\n",
       "      <td>[32, 95, 1, 20, 392, 7, 68, 4, 328, 33, 497, 5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092245</th>\n",
       "      <td>0</td>\n",
       "      <td>@smoochyfroggy You wellcome! Have a nice Day!</td>\n",
       "      <td>you wellcome  have a nice day</td>\n",
       "      <td>[8, 42399, 19, 4, 132, 33]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213310</th>\n",
       "      <td>1</td>\n",
       "      <td>Why is it so impossible to get an egg cream he...</td>\n",
       "      <td>why is it so impossible to get an egg cream he...</td>\n",
       "      <td>[110, 9, 6, 18, 2393, 2, 36, 93, 2444, 656, 86...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026205</th>\n",
       "      <td>0</td>\n",
       "      <td>lady at olive garden garden ask me if i cared ...</td>\n",
       "      <td>lady at olive garden garden ask me if i cared ...</td>\n",
       "      <td>[756, 25, 4727, 894, 894, 613, 17, 70, 1, 9128...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842287</th>\n",
       "      <td>0</td>\n",
       "      <td>Looking for domains. Great deals only.</td>\n",
       "      <td>looking for domains  great deals only</td>\n",
       "      <td>[209, 11, 10294, 99, 6290, 112]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292903</th>\n",
       "      <td>1</td>\n",
       "      <td>not wasting my money on a piercing that has a ...</td>\n",
       "      <td>not wasting my money on a piercing that has a ...</td>\n",
       "      <td>[26, 4254, 5, 414, 15, 4, 5087, 16, 100, 4, 10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137835</th>\n",
       "      <td>1</td>\n",
       "      <td>@rishil I think I'm the bigger geek as I found...</td>\n",
       "      <td>i think i m the bigger geek as i found that g...</td>\n",
       "      <td>[1, 77, 1, 20, 3, 2048, 2360, 83, 1, 320, 16, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468447</th>\n",
       "      <td>0</td>\n",
       "      <td>the only person who Jackson Rathbone (jasper) ...</td>\n",
       "      <td>the only person who jackson rathbone  jasper  ...</td>\n",
       "      <td>[3, 112, 536, 154, 3380, 23267, 8071, 116, 19,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692576</th>\n",
       "      <td>1</td>\n",
       "      <td>My Indian place is at farmer's market today!!!...</td>\n",
       "      <td>my indian place is at farmer s market today   ...</td>\n",
       "      <td>[5, 3174, 407, 9, 25, 6691, 12, 1713, 41, 21, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910387</th>\n",
       "      <td>0</td>\n",
       "      <td>@fancyfantastic you know I love you.</td>\n",
       "      <td>you know i love you</td>\n",
       "      <td>[8, 59, 1, 46, 8]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039469</th>\n",
       "      <td>0</td>\n",
       "      <td>don't want to go to work but i have to pay off...</td>\n",
       "      <td>don t want to go to work but i have to pay off...</td>\n",
       "      <td>[62, 14, 76, 2, 40, 2, 45, 21, 1, 19, 2, 564, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text  \\\n",
       "562641           1  Eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...   \n",
       "1596542          0                                      @SarY_ChaN      \n",
       "557121           1  Well, the question as to whether I should get ...   \n",
       "1176192          0                                 Picnic in the sun    \n",
       "1400171          0  Good morning! i'm outside and its a beautiful ...   \n",
       "1092245          0     @smoochyfroggy You wellcome! Have a nice Day!    \n",
       "213310           1  Why is it so impossible to get an egg cream he...   \n",
       "1026205          0  lady at olive garden garden ask me if i cared ...   \n",
       "842287           0            Looking for domains. Great deals only.    \n",
       "292903           1  not wasting my money on a piercing that has a ...   \n",
       "137835           1  @rishil I think I'm the bigger geek as I found...   \n",
       "1468447          0  the only person who Jackson Rathbone (jasper) ...   \n",
       "692576           1  My Indian place is at farmer's market today!!!...   \n",
       "910387           0              @fancyfantastic you know I love you.    \n",
       "1039469          0  don't want to go to work but i have to pay off...   \n",
       "\n",
       "                                                     text2  \\\n",
       "562641   eyes wide shzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...   \n",
       "1596542                                            chan      \n",
       "557121   well  the question as to whether i should get ...   \n",
       "1176192                                 picnic in the sun    \n",
       "1400171  good morning  i m outside and its a beautiful ...   \n",
       "1092245                    you wellcome  have a nice day     \n",
       "213310   why is it so impossible to get an egg cream he...   \n",
       "1026205  lady at olive garden garden ask me if i cared ...   \n",
       "842287             looking for domains  great deals only     \n",
       "292903   not wasting my money on a piercing that has a ...   \n",
       "137835    i think i m the bigger geek as i found that g...   \n",
       "1468447  the only person who jackson rathbone  jasper  ...   \n",
       "692576   my indian place is at farmer s market today   ...   \n",
       "910387                               you know i love you     \n",
       "1039469  don t want to go to work but i have to pay off...   \n",
       "\n",
       "                                                     text3  \\\n",
       "562641   [636, 1907, 1, 77, 212, 113, 4, 71, 9, 228, 15...   \n",
       "1596542                                             [5851]   \n",
       "557121   [74, 3, 957, 83, 2, 2288, 1, 135, 36, 31, 25, ...   \n",
       "1176192                                 [2392, 10, 3, 275]   \n",
       "1400171  [32, 95, 1, 20, 392, 7, 68, 4, 328, 33, 497, 5...   \n",
       "1092245                         [8, 42399, 19, 4, 132, 33]   \n",
       "213310   [110, 9, 6, 18, 2393, 2, 36, 93, 2444, 656, 86...   \n",
       "1026205  [756, 25, 4727, 894, 894, 613, 17, 70, 1, 9128...   \n",
       "842287                     [209, 11, 10294, 99, 6290, 112]   \n",
       "292903   [26, 4254, 5, 414, 15, 4, 5087, 16, 100, 4, 10...   \n",
       "137835   [1, 77, 1, 20, 3, 2048, 2360, 83, 1, 320, 16, ...   \n",
       "1468447  [3, 112, 536, 154, 3380, 23267, 8071, 116, 19,...   \n",
       "692576   [5, 3174, 407, 9, 25, 6691, 12, 1713, 41, 21, ...   \n",
       "910387                                   [8, 59, 1, 46, 8]   \n",
       "1039469  [62, 14, 76, 2, 40, 2, 45, 21, 1, 19, 2, 564, ...   \n",
       "\n",
       "                                                     text4  \n",
       "562641   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1596542  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "557121   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1176192  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1400171  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1092245  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "213310   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1026205  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "842287   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "292903   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "137835   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1468447  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "692576   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "910387   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1039469  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_limit = 200000\n",
    "max_words = 100000\n",
    "max_len = 1000\n",
    "\n",
    "def bloco():\n",
    "    \n",
    "    global df_original\n",
    "    global df_train\n",
    "    global df_test   \n",
    "   \n",
    "    # PARTE 1 - Limpa o texto \n",
    "    import re\n",
    "    pat1 = r'@[A-Za-z0-9]+'\n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "    pat3 = r'<.*?>'\n",
    "    pat4 = r'&.*?;'\n",
    "    pat = r'|'.join((pat1, pat2, pat3, pat4))\n",
    "    def tweet_cleaner(text):       \n",
    "        text = re.sub(pat,'',text)\n",
    "        try:\n",
    "            text = text.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "        except:\n",
    "            text = text\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "        text = text.lower()\n",
    "        return text\n",
    "\n",
    "    df_original['text2'] = df_original['text'].apply( tweet_cleaner )\n",
    "\n",
    "    \n",
    "    # PARTE 2 - Tokeniza usando o Keras\n",
    "    global tokenizer\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words,lower=True, split=\" \")\n",
    "    tokenizer.fit_on_texts(df_original['text2'])\n",
    "    #df_original['text3'] = tokenizer.texts_to_sequences(df_original['text2'])\n",
    "    #df_original['text4'] = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    #    df_original['text3'], \n",
    "    #    maxlen=max_len,\n",
    "    #    #padding='post',\n",
    "    #    #truncating='post'        \n",
    "    #).tolist()                                                                                                   \n",
    "   \n",
    "\n",
    "    global df_example\n",
    "    df_example = df_original.sample(15)\n",
    "    df_example['text3'] = tokenizer.texts_to_sequences(df_example['text2'])\n",
    "    df_example['text4'] = tf.keras.preprocessing.sequence.pad_sequences( df_example['text3'], maxlen=max_len ).tolist()              \n",
    "        \n",
    "    # PARTE 3 - Separa amostra de treinamento e de teste\n",
    "   \n",
    "    # 1 = train | 0 = test\n",
    "    df_original['rand'] = pd.Series([0,1]).sample(len(df_original), replace=True).array\n",
    "    \n",
    "    df_train_sz = 10000\n",
    "    df_train = df_original[ df_original[ 'rand' ] == 1 ]\n",
    "    df_train_positive = df_train[ df_train['sentiment'] == 0 ].sample(n=int(df_train_sz/2), replace=True)\n",
    "    df_train_negative = df_train[ df_train['sentiment'] == 1 ].sample(n=int(df_train_sz/2), replace=True)\n",
    "    df_train = pd.concat( [ df_train_negative, df_train_positive ] )    \n",
    "    df_train = df_train.sample(frac=1.0).reset_index(drop=True)\n",
    "    \n",
    "    df_test_sz = 40000\n",
    "    df_test = df_original[ df_original[ 'rand' ] == 0 ].sample(int(df_test_sz/2), replace=True)\n",
    "    df_test = df_test.sample(frac=1.0).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "bloco()\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07e57a-8455-4496-b901-75bf0a9c7a3a",
   "metadata": {},
   "source": [
    "Na tabela acima é possível ver os estagios da limpeza:\n",
    "* **text** contém o texto original da base \n",
    "* **text2** contém o texto após limpeza de tags, urls, nomes de usuário, números e minusculas\n",
    "* **text3** contém o texto codificado em \"embeddings\" pelo tensorflow. Cada palavra foi convertida em um número. \n",
    "* **text4** contém o texto codificado em \"embeddings\" com o padding. Só aparecem zeros aqui pois uma coluna com 1,2,3 em text3 será codificada como 0,0,0,0[...],1,2,3. Como é raro encontrar um tweet com mais de 180 palavras, o início é quase sempre [0,0,0,0,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287581a-38e5-450c-9d8f-ba1c83f12161",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4370bdf-cc7d-4c11-8c86-a689cddb5c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:10:51.808323: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-26 18:10:51.808364: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: lucas-n001\n",
      "2022-05-26 18:10:51.808373: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: lucas-n001\n",
      "2022-05-26 18:10:51.808466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.73.5\n",
      "2022-05-26 18:10:51.808490: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-05-26 18:10:51.808495: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.73.5\n",
      "2022-05-26 18:10:51.809087: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()         \n",
    "model.add(tf.keras.layers.Embedding(max_words, 50, mask_zero=True))\n",
    "model.add(tf.keras.layers.LSTM(4))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10907d22-fe7b-42f4-9113-8ef5c0b141e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 50)          5000000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 4)                 880       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                160       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,001,073\n",
      "Trainable params: 5,001,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "model.compile(\n",
    "    #optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001,momentum=0.5),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\n",
    "        'acc',        \n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tfa.metrics.F1Score(num_classes=1, threshold=0.5, name='f1')\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ffe26f-d9f7-4695-91b1-08d14b2b2971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(10000, 1000) y.shape=(10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences( tokenizer.texts_to_sequences( df_train['text2'] ), maxlen=max_len )\n",
    "y_train = df_train['sentiment'].values\n",
    "\n",
    "print( f'X.shape={X_train.shape} y.shape={y_train.shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf989e9-9000-43ea-b2da-efec2943078e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "27/27 [==============================] - 42s 1s/step - loss: 0.6930 - acc: 0.5199 - prec: 0.5223 - recall: 0.4998 - f1: 0.5108 - val_loss: 0.6929 - val_acc: 0.5440 - val_prec: 0.5389 - val_recall: 0.5334 - val_f1: 0.5361 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "27/27 [==============================] - 24s 880ms/step - loss: 0.6928 - acc: 0.5360 - prec: 0.5389 - recall: 0.5174 - f1: 0.5280 - val_loss: 0.6927 - val_acc: 0.5635 - val_prec: 0.5545 - val_recall: 0.5921 - val_f1: 0.5727 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "27/27 [==============================] - 24s 886ms/step - loss: 0.6926 - acc: 0.5469 - prec: 0.5481 - recall: 0.5496 - f1: 0.5488 - val_loss: 0.6925 - val_acc: 0.5750 - val_prec: 0.5742 - val_recall: 0.5405 - val_f1: 0.5568 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "27/27 [==============================] - 25s 904ms/step - loss: 0.6923 - acc: 0.5608 - prec: 0.5687 - recall: 0.5137 - f1: 0.5398 - val_loss: 0.6922 - val_acc: 0.5875 - val_prec: 0.5983 - val_recall: 0.5020 - val_f1: 0.5460 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "27/27 [==============================] - 20s 740ms/step - loss: 0.6918 - acc: 0.5826 - prec: 0.5964 - recall: 0.5189 - f1: 0.5550 - val_loss: 0.6918 - val_acc: 0.5995 - val_prec: 0.6099 - val_recall: 0.5253 - val_f1: 0.5644 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "27/27 [==============================] - 20s 746ms/step - loss: 0.6915 - acc: 0.5809 - prec: 0.5964 - recall: 0.5082 - f1: 0.5488 - val_loss: 0.6913 - val_acc: 0.6075 - val_prec: 0.6144 - val_recall: 0.5516 - val_f1: 0.5813 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "27/27 [==============================] - 26s 983ms/step - loss: 0.6909 - acc: 0.5964 - prec: 0.6049 - recall: 0.5628 - f1: 0.5831 - val_loss: 0.6908 - val_acc: 0.6135 - val_prec: 0.6349 - val_recall: 0.5121 - val_f1: 0.5669 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "27/27 [==============================] - 26s 948ms/step - loss: 0.6902 - acc: 0.6089 - prec: 0.6259 - recall: 0.5471 - f1: 0.5839 - val_loss: 0.6901 - val_acc: 0.6185 - val_prec: 0.6387 - val_recall: 0.5243 - val_f1: 0.5759 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "27/27 [==============================] - 27s 991ms/step - loss: 0.6892 - acc: 0.6198 - prec: 0.6369 - recall: 0.5626 - f1: 0.5974 - val_loss: 0.6893 - val_acc: 0.6230 - val_prec: 0.6403 - val_recall: 0.5405 - val_f1: 0.5862 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "27/27 [==============================] - 27s 990ms/step - loss: 0.6884 - acc: 0.6286 - prec: 0.6441 - recall: 0.5798 - f1: 0.6103 - val_loss: 0.6883 - val_acc: 0.6330 - val_prec: 0.6440 - val_recall: 0.5749 - val_f1: 0.6075 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.6872 - acc: 0.6379 - prec: 0.6566 - recall: 0.5828 - f1: 0.6175 - val_loss: 0.6871 - val_acc: 0.6345 - val_prec: 0.6455 - val_recall: 0.5769 - val_f1: 0.6093 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.6858 - acc: 0.6446 - prec: 0.6535 - recall: 0.6201 - f1: 0.6364 - val_loss: 0.6857 - val_acc: 0.6360 - val_prec: 0.6419 - val_recall: 0.5951 - val_f1: 0.6176 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "27/27 [==============================] - 27s 990ms/step - loss: 0.6840 - acc: 0.6481 - prec: 0.6585 - recall: 0.6199 - f1: 0.6386 - val_loss: 0.6841 - val_acc: 0.6425 - val_prec: 0.6508 - val_recall: 0.5962 - val_f1: 0.6223 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "27/27 [==============================] - 27s 986ms/step - loss: 0.6818 - acc: 0.6620 - prec: 0.6789 - recall: 0.6186 - f1: 0.6474 - val_loss: 0.6822 - val_acc: 0.6465 - val_prec: 0.6559 - val_recall: 0.5982 - val_f1: 0.6257 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.6795 - acc: 0.6656 - prec: 0.6793 - recall: 0.6314 - f1: 0.6544 - val_loss: 0.6800 - val_acc: 0.6480 - val_prec: 0.6574 - val_recall: 0.6002 - val_f1: 0.6275 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "27/27 [==============================] - 27s 994ms/step - loss: 0.6769 - acc: 0.6678 - prec: 0.6829 - recall: 0.6301 - f1: 0.6554 - val_loss: 0.6776 - val_acc: 0.6570 - val_prec: 0.6613 - val_recall: 0.6265 - val_f1: 0.6435 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "27/27 [==============================] - 27s 994ms/step - loss: 0.6733 - acc: 0.6786 - prec: 0.6893 - recall: 0.6540 - f1: 0.6712 - val_loss: 0.6748 - val_acc: 0.6600 - val_prec: 0.6667 - val_recall: 0.6235 - val_f1: 0.6444 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "27/27 [==============================] - 26s 973ms/step - loss: 0.6702 - acc: 0.6852 - prec: 0.6900 - recall: 0.6762 - f1: 0.6830 - val_loss: 0.6718 - val_acc: 0.6650 - val_prec: 0.6771 - val_recall: 0.6154 - val_f1: 0.6448 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.6664 - acc: 0.6938 - prec: 0.7051 - recall: 0.6692 - f1: 0.6867 - val_loss: 0.6683 - val_acc: 0.6675 - val_prec: 0.6757 - val_recall: 0.6285 - val_f1: 0.6513 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "27/27 [==============================] - 27s 998ms/step - loss: 0.6619 - acc: 0.6967 - prec: 0.7129 - recall: 0.6618 - f1: 0.6864 - val_loss: 0.6646 - val_acc: 0.6735 - val_prec: 0.6776 - val_recall: 0.6468 - val_f1: 0.6618 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "27/27 [==============================] - 27s 999ms/step - loss: 0.6576 - acc: 0.7036 - prec: 0.7111 - recall: 0.6889 - f1: 0.6998 - val_loss: 0.6604 - val_acc: 0.6805 - val_prec: 0.6847 - val_recall: 0.6549 - val_f1: 0.6694 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "27/27 [==============================] - 27s 998ms/step - loss: 0.6517 - acc: 0.7059 - prec: 0.7131 - recall: 0.6919 - f1: 0.7023 - val_loss: 0.6558 - val_acc: 0.6840 - val_prec: 0.6846 - val_recall: 0.6680 - val_f1: 0.6762 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "27/27 [==============================] - 26s 974ms/step - loss: 0.6452 - acc: 0.7147 - prec: 0.7183 - recall: 0.7094 - f1: 0.7138 - val_loss: 0.6508 - val_acc: 0.6875 - val_prec: 0.6881 - val_recall: 0.6721 - val_f1: 0.6800 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "27/27 [==============================] - 27s 995ms/step - loss: 0.6390 - acc: 0.7166 - prec: 0.7218 - recall: 0.7076 - f1: 0.7147 - val_loss: 0.6456 - val_acc: 0.6875 - val_prec: 0.6869 - val_recall: 0.6751 - val_f1: 0.6810 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "27/27 [==============================] - 27s 999ms/step - loss: 0.6321 - acc: 0.7236 - prec: 0.7279 - recall: 0.7168 - f1: 0.7223 - val_loss: 0.6400 - val_acc: 0.6920 - val_prec: 0.6871 - val_recall: 0.6913 - val_f1: 0.6892 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.6249 - acc: 0.7305 - prec: 0.7326 - recall: 0.7286 - f1: 0.7306 - val_loss: 0.6341 - val_acc: 0.6965 - val_prec: 0.6892 - val_recall: 0.7024 - val_f1: 0.6957 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.6173 - acc: 0.7325 - prec: 0.7299 - recall: 0.7408 - f1: 0.7353 - val_loss: 0.6281 - val_acc: 0.7015 - val_prec: 0.6926 - val_recall: 0.7115 - val_f1: 0.7019 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "27/27 [==============================] - 27s 992ms/step - loss: 0.6080 - acc: 0.7375 - prec: 0.7396 - recall: 0.7355 - f1: 0.7376 - val_loss: 0.6218 - val_acc: 0.7045 - val_prec: 0.6963 - val_recall: 0.7126 - val_f1: 0.7044 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.6005 - acc: 0.7462 - prec: 0.7479 - recall: 0.7453 - f1: 0.7466 - val_loss: 0.6155 - val_acc: 0.7060 - val_prec: 0.6976 - val_recall: 0.7146 - val_f1: 0.7060 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "27/27 [==============================] - 27s 999ms/step - loss: 0.5936 - acc: 0.7491 - prec: 0.7487 - recall: 0.7522 - f1: 0.7505 - val_loss: 0.6091 - val_acc: 0.7065 - val_prec: 0.6964 - val_recall: 0.7196 - val_f1: 0.7078 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "27/27 [==============================] - 27s 993ms/step - loss: 0.5824 - acc: 0.7541 - prec: 0.7527 - recall: 0.7592 - f1: 0.7559 - val_loss: 0.6024 - val_acc: 0.7115 - val_prec: 0.6997 - val_recall: 0.7287 - val_f1: 0.7139 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "27/27 [==============================] - 26s 977ms/step - loss: 0.5736 - acc: 0.7579 - prec: 0.7547 - recall: 0.7662 - f1: 0.7604 - val_loss: 0.5960 - val_acc: 0.7160 - val_prec: 0.7019 - val_recall: 0.7389 - val_f1: 0.7199 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "27/27 [==============================] - 27s 999ms/step - loss: 0.5632 - acc: 0.7644 - prec: 0.7589 - recall: 0.7769 - f1: 0.7678 - val_loss: 0.5893 - val_acc: 0.7175 - val_prec: 0.7028 - val_recall: 0.7419 - val_f1: 0.7218 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "27/27 [==============================] - 27s 999ms/step - loss: 0.5525 - acc: 0.7722 - prec: 0.7663 - recall: 0.7854 - f1: 0.7757 - val_loss: 0.5829 - val_acc: 0.7215 - val_prec: 0.7070 - val_recall: 0.7449 - val_f1: 0.7255 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "27/27 [==============================] - 27s 992ms/step - loss: 0.5429 - acc: 0.7788 - prec: 0.7765 - recall: 0.7846 - f1: 0.7806 - val_loss: 0.5765 - val_acc: 0.7205 - val_prec: 0.7068 - val_recall: 0.7419 - val_f1: 0.7240 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.5328 - acc: 0.7840 - prec: 0.7806 - recall: 0.7919 - f1: 0.7862 - val_loss: 0.5704 - val_acc: 0.7260 - val_prec: 0.7095 - val_recall: 0.7540 - val_f1: 0.7311 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.5223 - acc: 0.7899 - prec: 0.7838 - recall: 0.8023 - f1: 0.7930 - val_loss: 0.5645 - val_acc: 0.7280 - val_prec: 0.7143 - val_recall: 0.7490 - val_f1: 0.7312 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "27/27 [==============================] - 27s 1000ms/step - loss: 0.5124 - acc: 0.7911 - prec: 0.7898 - recall: 0.7951 - f1: 0.7924 - val_loss: 0.5590 - val_acc: 0.7285 - val_prec: 0.7117 - val_recall: 0.7571 - val_f1: 0.7337 - lr: 1.0000e-04\n",
      "Epoch 39/60\n",
      "27/27 [==============================] - 27s 991ms/step - loss: 0.5034 - acc: 0.7976 - prec: 0.7928 - recall: 0.8076 - f1: 0.8001 - val_loss: 0.5541 - val_acc: 0.7315 - val_prec: 0.7142 - val_recall: 0.7611 - val_f1: 0.7369 - lr: 1.0000e-04\n",
      "Epoch 40/60\n",
      "27/27 [==============================] - 26s 982ms/step - loss: 0.4933 - acc: 0.8055 - prec: 0.8002 - recall: 0.8158 - f1: 0.8079 - val_loss: 0.5495 - val_acc: 0.7330 - val_prec: 0.7142 - val_recall: 0.7662 - val_f1: 0.7393 - lr: 1.0000e-04\n",
      "Epoch 41/60\n",
      "27/27 [==============================] - 27s 993ms/step - loss: 0.4834 - acc: 0.8100 - prec: 0.8048 - recall: 0.8200 - f1: 0.8123 - val_loss: 0.5455 - val_acc: 0.7380 - val_prec: 0.7218 - val_recall: 0.7642 - val_f1: 0.7424 - lr: 1.0000e-04\n",
      "Epoch 42/60\n",
      "27/27 [==============================] - 26s 983ms/step - loss: 0.4756 - acc: 0.8123 - prec: 0.8071 - recall: 0.8220 - f1: 0.8145 - val_loss: 0.5422 - val_acc: 0.7385 - val_prec: 0.7200 - val_recall: 0.7702 - val_f1: 0.7443 - lr: 1.0000e-04\n",
      "Epoch 43/60\n",
      "27/27 [==============================] - 27s 996ms/step - loss: 0.4640 - acc: 0.8225 - prec: 0.8159 - recall: 0.8342 - f1: 0.8250 - val_loss: 0.5394 - val_acc: 0.7385 - val_prec: 0.7221 - val_recall: 0.7652 - val_f1: 0.7430 - lr: 1.0000e-04\n",
      "Epoch 44/60\n",
      "27/27 [==============================] - 27s 995ms/step - loss: 0.4570 - acc: 0.8194 - prec: 0.8119 - recall: 0.8328 - f1: 0.8222 - val_loss: 0.5374 - val_acc: 0.7415 - val_prec: 0.7254 - val_recall: 0.7672 - val_f1: 0.7457 - lr: 1.0000e-04\n",
      "Epoch 45/60\n",
      "27/27 [==============================] - 27s 999ms/step - loss: 0.4478 - acc: 0.8249 - prec: 0.8193 - recall: 0.8350 - f1: 0.8271 - val_loss: 0.5359 - val_acc: 0.7410 - val_prec: 0.7268 - val_recall: 0.7621 - val_f1: 0.7441 - lr: 1.0000e-04\n",
      "Epoch 46/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.4399 - acc: 0.8307 - prec: 0.8269 - recall: 0.8380 - f1: 0.8324 - val_loss: 0.5349 - val_acc: 0.7425 - val_prec: 0.7255 - val_recall: 0.7702 - val_f1: 0.7472 - lr: 1.0000e-04\n",
      "Epoch 47/60\n",
      "27/27 [==============================] - 27s 981ms/step - loss: 0.4331 - acc: 0.8401 - prec: 0.8344 - recall: 0.8500 - f1: 0.8421 - val_loss: 0.5343 - val_acc: 0.7445 - val_prec: 0.7282 - val_recall: 0.7702 - val_f1: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 48/60\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.4237 - acc: 0.8381 - prec: 0.8324 - recall: 0.8480 - f1: 0.8401 - val_loss: 0.5347 - val_acc: 0.7455 - val_prec: 0.7337 - val_recall: 0.7611 - val_f1: 0.7471 - lr: 1.0000e-04\n",
      "Epoch 49/60\n",
      "27/27 [==============================] - 27s 989ms/step - loss: 0.4162 - acc: 0.8451 - prec: 0.8438 - recall: 0.8482 - f1: 0.8460 - val_loss: 0.5351 - val_acc: 0.7455 - val_prec: 0.7245 - val_recall: 0.7824 - val_f1: 0.7523 - lr: 1.0000e-04\n",
      "Epoch 50/60\n",
      "27/27 [==============================] - 27s 998ms/step - loss: 0.4078 - acc: 0.8465 - prec: 0.8384 - recall: 0.8597 - f1: 0.8489 - val_loss: 0.5357 - val_acc: 0.7490 - val_prec: 0.7346 - val_recall: 0.7702 - val_f1: 0.7520 - lr: 8.0000e-05\n",
      "Epoch 51/60\n",
      "27/27 [==============================] - 27s 995ms/step - loss: 0.4007 - acc: 0.8499 - prec: 0.8456 - recall: 0.8572 - f1: 0.8513 - val_loss: 0.5367 - val_acc: 0.7475 - val_prec: 0.7324 - val_recall: 0.7702 - val_f1: 0.7509 - lr: 8.0000e-05\n",
      "Epoch 52/60\n",
      "27/27 [==============================] - 27s 997ms/step - loss: 0.3947 - acc: 0.8555 - prec: 0.8543 - recall: 0.8582 - f1: 0.8563 - val_loss: 0.5375 - val_acc: 0.7460 - val_prec: 0.7312 - val_recall: 0.7682 - val_f1: 0.7493 - lr: 6.4000e-05\n",
      "Epoch 53/60\n",
      "27/27 [==============================] - 27s 999ms/step - loss: 0.3850 - acc: 0.8591 - prec: 0.8570 - recall: 0.8632 - f1: 0.8601 - val_loss: 0.5387 - val_acc: 0.7465 - val_prec: 0.7333 - val_recall: 0.7652 - val_f1: 0.7489 - lr: 6.4000e-05\n",
      "Epoch 54/60\n",
      "27/27 [==============================] - 27s 991ms/step - loss: 0.3850 - acc: 0.8605 - prec: 0.8568 - recall: 0.8667 - f1: 0.8617 - val_loss: 0.5397 - val_acc: 0.7455 - val_prec: 0.7328 - val_recall: 0.7632 - val_f1: 0.7476 - lr: 5.1200e-05\n",
      "Epoch 55/60\n",
      "27/27 [==============================] - 24s 902ms/step - loss: 0.3771 - acc: 0.8636 - prec: 0.8616 - recall: 0.8674 - f1: 0.8645 - val_loss: 0.5408 - val_acc: 0.7440 - val_prec: 0.7329 - val_recall: 0.7581 - val_f1: 0.7453 - lr: 5.1200e-05\n",
      "Epoch 56/60\n",
      "27/27 [==============================] - 26s 964ms/step - loss: 0.3779 - acc: 0.8646 - prec: 0.8639 - recall: 0.8667 - f1: 0.8652 - val_loss: 0.5415 - val_acc: 0.7425 - val_prec: 0.7276 - val_recall: 0.7652 - val_f1: 0.7459 - lr: 4.0960e-05\n"
     ]
    }
   ],
   "source": [
    "my_callbacks = [\n",
    "        # abandona o processamento se a acurácia não melhorar em até {patitence} épocas\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_acc',patience=6), \n",
    "        # grava os modelos intermediários\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath='model/model.{epoch:02d}.h5'), # salva o modelo para poder retomar o treinamento\n",
    "        # grava informações para visualização\n",
    "        # tf.keras.callbacks.TensorBoard(log_dir='./logs'), \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, min_lr=0.00001)\n",
    "    ]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=60,\n",
    "    batch_size=300,\n",
    "    validation_split=0.20,\n",
    "    callbacks=my_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2887c40d-84c0-488f-b08d-084725b5c7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bloco():\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, ax = plt.subplots(2,1,figsize=(16,6))\n",
    "    ax[0].plot(history.history['val_loss'], color='#FF0000', label=\"val_loss\")\n",
    "    ax[0].plot(history.history['loss'], color='#FFA0A0', label=\"loss\")\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "        \n",
    "    ax[1].plot(history.history['val_acc'], color='#00FF00', label=\"val_acc\")\n",
    "    ax[1].plot(history.history['acc'], color='#A0FFA0', label=\"acc\")\n",
    "    ax[1].set_ylim([0.0,1.0])\n",
    "    legend = ax[1].legend(loc='best', shadow=True)        \n",
    "    \n",
    "bloco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5fc9b1-b997-4b00-9dc1-d7883d0d4f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seleciona o modelo com maior acurácia durante a validação (usualmente antes do overfit)\n",
      "melhor epoca: 50 val_acc=0.75\n"
     ]
    }
   ],
   "source": [
    "def bloco():\n",
    "    \n",
    "    print( 'Seleciona o modelo com maior acurácia durante a validação (usualmente antes do overfit)' )\n",
    "    \n",
    "    best_acc = max(history.history['val_acc'])\n",
    "    best_epoch = history.history['val_acc'].index(best_acc) + 1\n",
    "    \n",
    "    print( f'melhor epoca: {best_epoch} val_acc={best_acc:1.2f}' )    \n",
    "        \n",
    "    model.load_weights( f'model/model.{best_epoch:02d}.h5' )\n",
    "\n",
    "bloco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3082774-9c0e-4bc3-ab29-e2264ff2f4da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 54s 83ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi guys!  I have been dying to Tweet you.........</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watching the MTV awards wishing i was cool eno...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going to shop with my BFF today, it's gonn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alot of new pictures tweets  ; some really old...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scariest words ever, &amp;quot;Mommy, I cant breat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>ahhh Time to relax babies are in bed.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>@NarelleKylie I missed you  boohoo!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>I still cann't vote on Mr twitter. The &amp;quot;+...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>it is so hot that i am totally melting now</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>My boy came home with food.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  predicted\n",
       "0      Hi guys!  I have been dying to Tweet you.........          0          0\n",
       "1      watching the MTV awards wishing i was cool eno...          1          0\n",
       "2      I'm going to shop with my BFF today, it's gonn...          0          0\n",
       "3      alot of new pictures tweets  ; some really old...          0          0\n",
       "4      Scariest words ever, &quot;Mommy, I cant breat...          1          1\n",
       "...                                                  ...        ...        ...\n",
       "19995             ahhh Time to relax babies are in bed.           0          0\n",
       "19996                @NarelleKylie I missed you  boohoo!          1          1\n",
       "19997  I still cann't vote on Mr twitter. The &quot;+...          1          1\n",
       "19998       it is so hot that i am totally melting now            1          1\n",
       "19999                       My boy came home with food.           0          1\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tf.keras.preprocessing.sequence.pad_sequences( tokenizer.texts_to_sequences( df_test['text2'] ), maxlen=max_len )\n",
    "y_test = df_test['sentiment'].values\n",
    "y_pred = [ 1 if y_pred > 0.5 else 0 for y_pred in model.predict(X_test).reshape(len(X_test)) ]\n",
    "\n",
    "df_test['predicted'] = y_pred\n",
    "df_test[ ['text','sentiment','predicted'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7b78808-bba4-4c29-ba9b-41103ea63cc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "        <style>\n",
       "           .luc_confusion_mtx td { background: white!IMPORTANT; border: 0pt !IMPORTANT; text-align: center!IMPORTANT }           \n",
       "           td.luc_confusion_mtx_dp { width: 90pt; height: 90pt; background: #c0ffc0!IMPORTANT; border: 1pt solid black!IMPORTANT } \n",
       "           td.luc_confusion_mtx_dn { width: 90pt; height: 90pt; background: #ffc0c0!IMPORTANT; border: 1pt solid black!IMPORTANT }            \n",
       "        </style>\n",
       "        \n",
       "               \n",
       "        <table class='luc_confusion_mtx'>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td colspan=2>Previsão</td>\n",
       "            <td></td>\n",
       "            <td rowspan=5 style='text-align: left!IMPORTANT'>\n",
       "                    Acurácia<br><big><big>(TP+TN)/(total)</big></big> = 14874/20000 = <big>74.4%</big><br>\n",
       "                    <br><br>\n",
       "                    Considerando que as duas classes (0=sentimento negativo;1=sentimento positivo) tem igual \n",
       "                    valor para esta análise, é importante maximizar a diagonal verde / minimizar a diagonal vermelha,\n",
       "                    portanto os indicadores de Acurácia OU F1 são os mais indicados.<br>\n",
       "                    <br>\n",
       "                    Os indicadores de precisão e sensibilidade(recall) podem ser usados em conjunto, mas não são\n",
       "                    muito intuitivos para este conjunto de dados pois mensuram da perspectiva do \"sentimento positivo\".\n",
       "                    Em outras palavras, a sensibilidade indica quantos \"sentimentos positivos\" corretos foram encontrados\n",
       "                    e a \"precisão\" indica do total apontado pelo modelo como \"sentimento positivo\", quantos eram. \n",
       "            </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td>Negativo</td>\n",
       "            <td>Positivo</td>\n",
       "            <td></td>            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td rowspan=2>Real</td>\n",
       "            <td>Negativo</td>\n",
       "            <td class=\"luc_confusion_mtx_dp\"><big><big>TN</big></big><br>7252<br>36.3%</td>\n",
       "            <td class=\"luc_confusion_mtx_dn\"><big><big>FP</big></big><br>2641<br>13.2%</td>\n",
       "            <td>9893</td>\n",
       "        </tr>        \n",
       "        <tr>\n",
       "            <td>Positivo</td>\n",
       "            <td class=\"luc_confusion_mtx_dn\"><big><big>FN</big></big><br>2485<br>12.4%</td>\n",
       "            <td class=\"luc_confusion_mtx_dp\"><big><big>TP</big></big><br>7622<br>38.1%</td>\n",
       "            <td>5126</td>\n",
       "        </tr>  \n",
       "        <tr>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "            <td>9737</td>\n",
       "            <td>10263</td>\n",
       "            <td>20000</td>\n",
       "        </tr>  \n",
       "        </table>    \n",
       "        \n",
       "        \n",
       "       \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Acurácia=74.37% dos apontamentos positivos e negativos estão corretos\n",
      " Recall/Sensibilidade=75.41% dos sentimentos positivos da base foram apontados\n",
      "             Precisão=74.27% dos sentimentos positivos apontados estão corretos\n",
      "             F1 Score=74.89% média harmônica da acurácia e recall\n"
     ]
    }
   ],
   "source": [
    "def block():\n",
    "    \n",
    "    global confusion_mtx\n",
    "    global confusion_mtx_pc\n",
    "    \n",
    "    confusion_mtx = tf.math.confusion_matrix( y_test, y_pred )\n",
    "\n",
    "    confusion_mtx = pd.DataFrame( confusion_mtx )\n",
    "    confusion_mtx.loc['Total'] = confusion_mtx.sum(numeric_only=True) \n",
    "    confusion_mtx['total'] = confusion_mtx[0] + confusion_mtx[1]\n",
    "    \n",
    "    confusion_mtx_pc = confusion_mtx / len(y_test)\n",
    "    \n",
    "    fp = confusion_mtx.iloc[0,1] \n",
    "    fn = confusion_mtx.iloc[1,0]\n",
    "    tn = confusion_mtx.iloc[0,0]\n",
    "    tp = confusion_mtx.iloc[1,1] \n",
    "    \n",
    "    total = (tp+tn+fp+fn)\n",
    "    \n",
    "    acc       = (tp+tn)/(tp+tn+fp+fn)\n",
    "    recall    = tp/(tp+fn)\n",
    "    f1        = (2*acc*recall)/(acc+recall)\n",
    "    \n",
    "    fdr  = fp/(fp+tp)\n",
    "    fnr  = fn/(fn+tp)\n",
    "    \n",
    "    tpr = tp/(fn+tp)\n",
    "    ppv  = tp/(fp+tp)\n",
    "    \n",
    "    \n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(f\"\"\"\n",
    "    \n",
    "        <style>\n",
    "           .luc_confusion_mtx td {{ background: white!IMPORTANT; border: 0pt !IMPORTANT; text-align: center!IMPORTANT }}           \n",
    "           td.luc_confusion_mtx_dp {{ width: 90pt; height: 90pt; background: #c0ffc0!IMPORTANT; border: 1pt solid black!IMPORTANT }} \n",
    "           td.luc_confusion_mtx_dn {{ width: 90pt; height: 90pt; background: #ffc0c0!IMPORTANT; border: 1pt solid black!IMPORTANT }}            \n",
    "        </style>\n",
    "        \n",
    "               \n",
    "        <table class='luc_confusion_mtx'>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td colspan=2>Previsão</td>\n",
    "            <td></td>\n",
    "            <td rowspan=5 style='text-align: left!IMPORTANT'>\n",
    "                    Acurácia<br><big><big>(TP+TN)/(total)</big></big> = {tp+tn}/{total} = <big>{(tp+tn)*100.0/total:2.1f}%</big><br>\n",
    "                    <br><br>\n",
    "                    Considerando que as duas classes (0=sentimento negativo;1=sentimento positivo) tem igual \n",
    "                    valor para esta análise, é importante maximizar a diagonal verde / minimizar a diagonal vermelha,\n",
    "                    portanto os indicadores de Acurácia OU F1 são os mais indicados.<br>\n",
    "                    <br>\n",
    "                    Os indicadores de precisão e sensibilidade(recall) podem ser usados em conjunto, mas não são\n",
    "                    muito intuitivos para este conjunto de dados pois mensuram da perspectiva do \"sentimento positivo\".\n",
    "                    Em outras palavras, a sensibilidade indica quantos \"sentimentos positivos\" corretos foram encontrados\n",
    "                    e a \"precisão\" indica do total apontado pelo modelo como \"sentimento positivo\", quantos eram. \n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>Negativo</td>\n",
    "            <td>Positivo</td>\n",
    "            <td></td>            \n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td rowspan=2>Real</td>\n",
    "            <td>Negativo</td>\n",
    "            <td class=\"luc_confusion_mtx_dp\"><big><big>TN</big></big><br>{tn}<br>{tn*100.0/total:2.1f}%</td>\n",
    "            <td class=\"luc_confusion_mtx_dn\"><big><big>FP</big></big><br>{fp}<br>{fp*100.0/total:2.1f}%</td>\n",
    "            <td>{tn+fp}</td>\n",
    "        </tr>        \n",
    "        <tr>\n",
    "            <td>Positivo</td>\n",
    "            <td class=\"luc_confusion_mtx_dn\"><big><big>FN</big></big><br>{fn}<br>{fn*100.0/total:2.1f}%</td>\n",
    "            <td class=\"luc_confusion_mtx_dp\"><big><big>TP</big></big><br>{tp}<br>{tp*100.0/total:2.1f}%</td>\n",
    "            <td>{fn+fp}</td>\n",
    "        </tr>  \n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td>{tn+fn}</td>\n",
    "            <td>{fp+tp}</td>\n",
    "            <td>{total}</td>\n",
    "        </tr>  \n",
    "        </table>    \n",
    "        \n",
    "        \n",
    "       \n",
    "    \"\"\"))        \n",
    "    \n",
    "    print( f'             Acurácia={acc*100.0:05.2f}% dos apontamentos positivos e negativos estão corretos' )\n",
    "    print( f' Recall/Sensibilidade={tpr*100.0:05.2f}% dos sentimentos positivos da base foram apontados' )   \n",
    "    print( f'             Precisão={ppv*100.0:05.2f}% dos sentimentos positivos apontados estão corretos' )    \n",
    "    print( f'             F1 Score={f1*100.0:05.2f}% média harmônica da acurácia e recall' )        \n",
    "      \n",
    "\n",
    "    \n",
    "block()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b8407-9462-4823-9496-e6da6f55d6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "venv_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
